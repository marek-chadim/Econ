{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXZGemzS5SR_"
      },
      "source": [
        "# Fairness and Bias in Machine Learning\n",
        "\n",
        "Today, we will reproduce part of the analysis performed by ProPublica about the COMPAS algorithm, which is used to predict the probability of recidivism (i.e. committing a crime in the future after the current one)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPAS Algorithm"
      ],
      "metadata": {
        "id": "LqHmKVhL9avX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The COMPAS algorithm, which stands for **Correctional Offender Management Profiling for Alternative Sanctions**, is essentially a tool used to predict the likelihood of a criminal defendant reoffending - that is, committing another crime in the future.\n",
        "\n",
        "Here's an analogy to help explain: Imagine you're trying to predict the weather. You might look at things like the current temperature, humidity, wind speed, and so on. Then, based on that information, you make a prediction: Is it going to rain later today, or not?\n",
        "\n",
        "The COMPAS algorithm works in a similar way, but instead of predicting the weather, it's predicting a person's behavior. It looks at various factors about a person, such as **their age, their criminal history, and their responses to a questionnaire**. Based on these factors, the algorithm makes a prediction: Is this person likely to commit another crime in the future, or not?\n",
        "\n",
        "These predictions are then used to **help judges make decisions in criminal cases**. For example, a judge might use the prediction to help decide whether a defendant should be released on bail before their trial, or to help decide what sentence to give a defendant who's been found guilty.\n",
        "\n",
        "However, the COMPAS algorithm has been **controversial**. A 2016 investigation by ProPublica, a non-profit investigative journalism organization, found that the **algorithm was biased against black defendants**. The algorithm predicted that black defendants were more likely to reoffend than they actually were, and less likely to predict that white defendants would reoffend than they actually did. This has sparked a lot of debate about the use of algorithms in the criminal justice system, and how to ensure that these algorithms are fair."
      ],
      "metadata": {
        "id": "jxxltKAf8-hd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z96fHtIW8G5z"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEwxAf738G5z"
      },
      "source": [
        "Let's import the libraries we will need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhIpCPYh5SSC",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:10.557502900Z",
          "start_time": "2023-05-24T18:59:10.547920300Z"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.rcParams[\"figure.figsize\"] = [11, 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUZrVNC85SSD"
      },
      "source": [
        "Then we can load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwRPrXYs5SSD",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:14.101258600Z",
          "start_time": "2023-05-24T18:59:14.014190100Z"
        }
      },
      "outputs": [],
      "source": [
        "df_raw = pd.read_csv(\"../data/compas-scores-two-years.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3_VqUds5SSD",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:14.271231400Z",
          "start_time": "2023-05-24T18:59:14.214189700Z"
        }
      },
      "outputs": [],
      "source": [
        "df_raw.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYi8llcJ5SSE"
      },
      "source": [
        "## Column selection\n",
        "\n",
        "We will limit our analysis to the following columns:\n",
        "\n",
        "- **id**: defendant identifier\n",
        "- **sex**: The defendant's sex (Male or Female)\n",
        "- **age**: The defendant's age\n",
        "- **age_cat**: A categorical representation of the defendant's age, often binned into age groups for easier analysis.\n",
        "- **race**: The defendant's race.\n",
        "- **days_b_screening_arrest**: The number of days between the COMPAS screening date and the date of the defendant's arrest.\n",
        "- **c_charge_degree**: The degree of the crime the defendant is charged with (F : felony, M : misdemeanor)\n",
        "- **priors_count**: number of previous offenses\n",
        "- **decile_score**: This is a score, ranging from 1 to 10, given by the COMPAS tool. The score represents the perceived risk that a defendant will re-offend. Higher scores indicate a higher perceived risk.\n",
        "- **score_text**: A textual description of the risk score. This can be 'Low', 'Medium', or 'High'.\n",
        "- **c_jail_in**: The date and time the defendant entered jail\n",
        "- **c_jail_out**: The date and time the defendant left jail\n",
        "- **is_recid**: This is a binary field that indicates whether the defendant is a recidivist, i.e., whether they re-offended after the COMPAS assessment. A value of 1 indicates that they did re-offend, while a value of 0 indicates that they did not.\n",
        "- **two_year_recid**: A binary field that indicates whether the defendant re-offended within two years after the COMPAS assessment. A value of 1 indicates that they did re-offend, while a value of 0 indicates that they did not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qToTpcC5SSF",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:15.593036100Z",
          "start_time": "2023-05-24T18:59:15.546034100Z"
        }
      },
      "outputs": [],
      "source": [
        "columns_of_interest = [\"id\", \"sex\", \"age\", \"age_cat\", \"race\", \"days_b_screening_arrest\",\n",
        "                       \"c_charge_degree\", \"priors_count\", \"decile_score\", \"score_text\", \"v_score_text\",\n",
        "                       \"c_jail_in\", \"c_jail_out\", \"is_recid\", \"two_year_recid\"]\n",
        "df = df_raw[columns_of_interest].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhWgJYhA5SSG"
      },
      "source": [
        "### Before starting the analysis, ProPublica performed a cleaning of some rows because of missing data:\n",
        "\n",
        "> There are a number of reasons remove rows because of missing data:\n",
        "> - If the charge date of a defendants COMPAS scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
        "> - We coded the recidivist flag -- is_recid -- to be -1 if we could not find a COMPAS case at all.\n",
        "> - In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
        "> - We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_llPwZ_5SSG",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:16.642875900Z",
          "start_time": "2023-05-24T18:59:16.601747Z"
        }
      },
      "outputs": [],
      "source": [
        "# Applying the filter used by ProPublica\n",
        "# creating a filter (or mask) to select certain rows from the dataframe df based on specific conditions.\n",
        "selection = ((df[\"days_b_screening_arrest\"] <= 30) & (df[\"days_b_screening_arrest\"] >= -30)\n",
        "            & (df[\"is_recid\"] != -1)\n",
        "            & (df[\"c_charge_degree\"] != \"O\")\n",
        "            & (df[\"score_text\"] != \"N/A\"))\n",
        "\n",
        "'''\n",
        "df[\"days_b_screening_arrest\"] <= 30 and df[\"days_b_screening_arrest\"] >= -30: This selects the records where the number of days between the COMPAS screening date and the date of arrest is within 30 days before or after the screening.\n",
        "\n",
        "df[\"is_recid\"] != -1: This selects the records where is_recid (which indicates whether the person is a recidivist, i.e., a repeat offender) is not equal to -1. A value of -1 here may indicate missing or erroneous data.\n",
        "\n",
        "df[\"c_charge_degree\"] != \"O\": This selects the records where the charge degree is not 'O'.\n",
        "\n",
        "df[\"score_text\"] != \"N/A\": This selects the records where the score_text (the text description of the risk score) is not 'N/A'. 'N/A' usually means 'Not Available', indicating missing data.\n",
        "'''\n",
        "\n",
        "df = df[selection].copy()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5QAKliU5SSH",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:17.372161200Z",
          "start_time": "2023-05-24T18:59:17.317103100Z"
        }
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0KWNc5y5SSI"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ebc2kFv5SSI"
      },
      "source": [
        "Distribution by age:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QvvDEk15SSJ",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:18.584760500Z",
          "start_time": "2023-05-24T18:59:18.560637400Z"
        }
      },
      "outputs": [],
      "source": [
        "df.age_cat.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMJnVxk5SSJ"
      },
      "source": [
        "We can also get the normalised values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lngxxOC5SSK",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:19.475867Z",
          "start_time": "2023-05-24T18:59:19.458816300Z"
        }
      },
      "outputs": [],
      "source": [
        "df.age_cat.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J95j_LQy5SSK"
      },
      "source": [
        "Of course, we could create a visualisation of these values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmOeSaaN5SSL",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:20.605292700Z",
          "start_time": "2023-05-24T18:59:20.476162100Z"
        }
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=df[\"age_cat\"], color=\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPFlky0W5SSL"
      },
      "source": [
        "We can also specifie a `hue` parameter to separate each count stack into different bars (depending on another feature):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQjDDerh5SSL",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:22.423650500Z",
          "start_time": "2023-05-24T18:59:22.402460800Z"
        }
      },
      "outputs": [],
      "source": [
        "# sns.countplot(x=\"age_cat\", hue=\"score_text\", data=df)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubYb8nST5SSL"
      },
      "source": [
        "Distributions by race"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuPnREnz5SSM",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:22.963814500Z",
          "start_time": "2023-05-24T18:59:22.870973200Z"
        }
      },
      "outputs": [],
      "source": [
        "display(df[\"race\"].value_counts())\n",
        "plt.rcParams['figure.figsize'] = [11, 4]\n",
        "sns.countplot(x=df[\"race\"], color=\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dVgo10jRBrg",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:23.608452Z",
          "start_time": "2023-05-24T18:59:23.585135100Z"
        }
      },
      "outputs": [],
      "source": [
        "# sns.countplot(x=\"race\", hue=\"score_text\", data=df)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gSprIra5SSO"
      },
      "source": [
        "Let's see now the text-based score values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05RfpEeC5SSP",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:24.161573300Z",
          "start_time": "2023-05-24T18:59:24.133389900Z"
        }
      },
      "outputs": [],
      "source": [
        "df.score_text.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFu6eKab5SSP"
      },
      "source": [
        "COMPAS also tries to predict if recivism will be violent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDjS4mzC5SSP",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:25.384242300Z",
          "start_time": "2023-05-24T18:59:25.342421800Z"
        }
      },
      "outputs": [],
      "source": [
        "df.v_score_text.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYGrZRBT5SSQ"
      },
      "source": [
        "Lastly, the dataset is mostly composed by men:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7JxO7db5SSQ",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:26.345595Z",
          "start_time": "2023-05-24T18:59:26.330774300Z"
        }
      },
      "outputs": [],
      "source": [
        "df.sex.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRvVF3ba5SSR"
      },
      "source": [
        "### Correlation between COMPAS score and jail duration\n",
        "\n",
        "From the article:\n",
        "\n",
        "> In 2008, the sheriff’s office decided that instead of building another jail, it would begin using Northpointe’s risk scores (e.g. COMPAS) to help identify which defendants were low risk enough to be released on bail pending trial. Since then, nearly everyone arrested in Broward has been scored soon after being booked. (People charged with murder and other capital crimes are not scored because they are not eligible for pretrial release.)\n",
        "\n",
        "Based on this, it would be expected to find a correlation between jail time and the score provided by COMPAS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U_xq7lP5SSS"
      },
      "source": [
        "Let's calculate the correlation between the jail time and the decile score of a defendant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re7WlFZq5SSS",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:27.931491100Z",
          "start_time": "2023-05-24T18:59:27.888750400Z"
        }
      },
      "outputs": [],
      "source": [
        "# Convert jail date columns to the appropriate type for operating with them\n",
        "for col in [\"c_jail_in\", \"c_jail_out\"]:\n",
        "    df[col] = pd.to_datetime(df[col])\n",
        "\n",
        "df[[\"c_jail_in\", \"c_jail_out\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df0idtNo5SSS",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:28.527007200Z",
          "start_time": "2023-05-24T18:59:28.458835900Z"
        }
      },
      "outputs": [],
      "source": [
        "def get_jail_duration_days(row):\n",
        "  return (row[\"c_jail_out\"] - row[\"c_jail_in\"]).days\n",
        "\n",
        "df[\"jail_duration_days\"] = df.apply(get_jail_duration_days, axis=1)\n",
        "df[\"jail_duration_days\"].corr(df[\"decile_score\"])\n",
        "\n",
        "# Above code can also be written this way:\n",
        "# print(df[\"decile_score\"].corr(df[\"jail_duration_days\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In statistical terms, a correlation coefficient (often denoted by \"r\") ranges from -1 to +1. The closer the value is to +1 or -1, the stronger the relationship between the variables. A correlation of +1 indicates a perfect positive relationship, a correlation of -1 indicates a perfect negative relationship, and a correlation of 0 indicates no relationship.\n",
        "\n",
        "Here's a general guide to interpreting correlation coefficient values:\n",
        "\n",
        "1. Very strong relationship (±0.8 to ±1.0)\n",
        "2. Strong relationship (±0.6 to ±0.8)\n",
        "3. Moderate relationship (±0.4 to ±0.6)\n",
        "4. Weak relationship (±0.2 to ±0.4)\n",
        "5. Very weak or no relationship (0 to ±0.2)\n",
        "\n",
        "In this case, a correlation coefficient of 0.2075 would suggest a weak positive relationship between decile_score and jail_duration_days. This means that as the decile_score increases, the jail_duration_days tends to slightly increase as well, but the relationship is not very strong. This suggests that other factors apart from the decile_score also significantly influence the jail_duration_days. It also indicates that the decile_score alone cannot be used to predict the jail_duration_days reliably."
      ],
      "metadata": {
        "id": "nwi1C18oDJ9w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWkUTO8R5SSS"
      },
      "source": [
        "We can also use seaborn's `regplot` that you have learned in the previous lectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSuKUtLG5SST",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:33.990136500Z",
          "start_time": "2023-05-24T18:59:33.718002600Z"
        }
      },
      "outputs": [],
      "source": [
        "sns.regplot(x=df[\"decile_score\"], y=df[\"jail_duration_days\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaODZWtS5SST"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Can we extrapolate anything from this relation? Can we conclude that COMPAS is increasing jail time?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**"
      ],
      "metadata": {
        "id": "9CmlHMsuDof6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4g1k1XG5SSU"
      },
      "source": [
        "**What can we conclude then?**\n",
        "\n",
        "There is a slight positive correlation between the total jail duration and the COMPAS recidivism score*. Nothing more, nothing less"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGzeG1Cl5SSU"
      },
      "source": [
        "### Distribution of recidivism numeric scores depending on race:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QBqrOqY5SSU",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:46.596651700Z",
          "start_time": "2023-05-24T18:59:46.472736300Z"
        }
      },
      "outputs": [],
      "source": [
        "df_black = df[df.race == \"African-American\"]\n",
        "sns.countplot(x=df_black[\"decile_score\"], color=\"green\")\n",
        "plt.ylim(0, 650)\n",
        "plt.title(\"African-American Defendants' Decile Scores\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GDncl9H5SSU"
      },
      "source": [
        "**Exercise**: Create the same count plot visualisation for the `Caucasian` rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHnXJTHl5SSV",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:47.999651800Z",
          "start_time": "2023-05-24T18:59:47.836651900Z"
        }
      },
      "outputs": [],
      "source": [
        "# Your turn: create a countplot for Caucasian\n",
        "df_white = df[df.race == \"Caucasian\"]\n",
        "sns.countplot(x=df_white[\"decile_score\"], color=\"green\")\n",
        "plt.ylim(0, 650)\n",
        "plt.title(\"Caucasian Defendants' Decile Scores\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_WEWoWh5SSW"
      },
      "source": [
        "What can we say about the difference between these plots?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGbrVMH5SSW"
      },
      "source": [
        "# Analysis of accuracy for the COMPAS classification\n",
        "\n",
        "The accuracy is similar for the different races (~60%), but there seems to be an issue on how the algorithm fails to predict a value:\n",
        "    \n",
        "- African American are more prone to **false positives**, i.e., being incorrectly classified as \"high risk\" (and not reoffending later)\n",
        "- On the contrary, caucasian/white defendants suffer from the opposite treatment, with a high number of **false negatives**: they are more likely to be wrongly labeled as \"low risk\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pECpLMBR5SSW"
      },
      "source": [
        "We will create a `high_risk` binary column: this value will be 0 if `score_text` is \"Low\", and 1 for the \"Medium\" and \"High\" values. We will use this column as the predicted outcome of the COMPAS algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6mpkL5AVV93",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:50.062445400Z",
          "start_time": "2023-05-24T18:59:50.030115100Z"
        }
      },
      "outputs": [],
      "source": [
        "df[\"score_text\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKomnF145SSW",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:50.674089200Z",
          "start_time": "2023-05-24T18:59:50.658131400Z"
        }
      },
      "outputs": [],
      "source": [
        "def get_high_risk(score_text_value):\n",
        "  if score_text_value == \"Low\":\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "df[\"high_risk\"] = df[\"score_text\"].apply(get_high_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIE4y05e5SSW",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:50.995969800Z",
          "start_time": "2023-05-24T18:59:50.909970800Z"
        }
      },
      "outputs": [],
      "source": [
        "df[[\"decile_score\", \"score_text\", \"high_risk\"]].drop_duplicates().sort_values(by=[\"decile_score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bkgx-So5SSW"
      },
      "source": [
        "Our truth column is `is_recid`, which indicates whether a defendant commited a new crime after the first one.\n",
        "\n",
        "As we have both the COMPAS prediction and the real outcome, we can check how well the score performs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa0lv_Sj5SSW",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:52.268175Z",
          "start_time": "2023-05-24T18:59:52.009441300Z"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "real = df[\"is_recid\"]\n",
        "predicted = df[\"high_risk\"]\n",
        "\n",
        "print(classification_report(real, predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDVubBW15SSW"
      },
      "source": [
        "Do these metrics change for race subsets? [Relevant image](https://en.wikipedia.org/wiki/File:Precisionrecall.svg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y8feOzv5SSX",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:52.834651800Z",
          "start_time": "2023-05-24T18:59:52.818466900Z"
        }
      },
      "outputs": [],
      "source": [
        "df_white = df[df.race == \"Caucasian\"]\n",
        "print(classification_report(df_white[\"is_recid\"], df_white[\"high_risk\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C4NDfUY5SSX"
      },
      "source": [
        "**Exercise**: do the same for `African-American` defendants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBEqspuY5SSX",
        "ExecuteTime": {
          "end_time": "2023-05-24T18:59:53.698142600Z",
          "start_time": "2023-05-24T18:59:53.651206200Z"
        }
      },
      "outputs": [],
      "source": [
        "# Your turn: obtain a classification_report for the subset of African-American defendants\n",
        "df_black = df[df.race == \"African-American\"]\n",
        "print(classification_report(df_black[\"is_recid\"], df_black[\"high_risk\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-EVh9bA5SSb"
      },
      "source": [
        "This and (many many) other metrics can be calculated with existing fairness tools, such as the one explained next. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qiYkPZL5SSb"
      },
      "source": [
        "# Analysing fairness and bias with an existing library: Fairlearn\n",
        "\n",
        "[Fairlearn](https://fairlearn.org/) is one of the available tools (more at the end of this notebook) to evaluate the fairness of a classifier. It also includes methods to both train a dataset trying to avoid biases, and to try mitigate issues of an unfair dataset a posteriori (i.e. after training)\n",
        "\n",
        "The process of using fairlearn involves the following steps:\n",
        "\n",
        "- Determine the metrics to evaluate (e.g. accuracy, false positive/negative rates)\n",
        "- Knowing both the predictions and the true values of the outcome (e.g. `high_risk` and `is_recid`)\n",
        "- Indicating the sensitive features (e.g. race)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkSpSPQD5SSb"
      },
      "source": [
        "As metrics, we will use the support (i.e. number of rows in the subgroup), the selection rate (i.e. number of \"positive\" outcomes, in our case of high risk predictions), accuracy, false positive rate and false negative rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1cQeQkN5SSb",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:10.503484400Z",
          "start_time": "2023-05-24T19:00:08.131687500Z"
        }
      },
      "outputs": [],
      "source": [
        "!pip install fairlearn\n",
        "\n",
        "from fairlearn.metrics import MetricFrame\n",
        "from fairlearn.metrics import selection_rate, false_negative_rate, false_positive_rate\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# We can define our own metrics if not present in a library.\n",
        "# Functions need to take true and predicted outcomes as parameters\n",
        "def support(y_true, y_score):\n",
        "    return len(y_true)\n",
        "\n",
        "metrics = {'support': support, \n",
        "           'selection_rate': selection_rate,\n",
        "           'accuracy': accuracy_score,\n",
        "           'FNR': false_negative_rate, \n",
        "           'FPR': false_positive_rate}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2-pEu8Q5SSb"
      },
      "source": [
        "Now we create a `MetricsFrame` instance using `race` as the sensitive feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn1arGzA5SSc",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:13.263897800Z",
          "start_time": "2023-05-24T19:00:13.199656200Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_by_race = MetricFrame(metrics,\n",
        "                         df[\"is_recid\"],  # the real outcome\n",
        "                         df[\"high_risk\"], # the predicted outcome\n",
        "                         sensitive_features=df[\"race\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0yoDx4g5SSc"
      },
      "source": [
        "We can get a look at the general metrics values with the `overall` attribute. You can check whether the following values match the ones we calculated some cells above (they should):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpMHERHu5SSc",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:14.575397600Z",
          "start_time": "2023-05-24T19:00:14.543871200Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_by_race.overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S9IV8zG5SSc"
      },
      "source": [
        "Now, we can get the feature values for every group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KScw2x3M5SSc",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:15.486469500Z",
          "start_time": "2023-05-24T19:00:15.473468Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_by_race.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSgVBzG85SSd"
      },
      "source": [
        "The library also includes easy ways to plot those results:\n",
        "\n",
        "Is there anything in those plots that catches your attention?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHtFRcGO5SSd",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:17.118015800Z",
          "start_time": "2023-05-24T19:00:16.452127800Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_by_race.by_group.plot.bar(subplots=True, figsize=(10, 14))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrSNdnyn5SSd"
      },
      "source": [
        "In the previous calculations, the fact that some of the race groups are very poorly represented in the dataset altered the results (e.g. when calculating maximum differences between groups). We will re-create the metric frame but only for `Caucasian`, `African-American` and `Hispanic` defendants: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k28SlyUT5SSd",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:17.388229700Z",
          "start_time": "2023-05-24T19:00:17.332183900Z"
        }
      },
      "outputs": [],
      "source": [
        "df_filtered = df[df[\"race\"].isin([\"Caucasian\", \"African-American\", \"Hispanic\"])]\n",
        "mf_by_race = MetricFrame(metrics,\n",
        "                         df_filtered[\"is_recid\"],  # the real outcome\n",
        "                         df_filtered[\"high_risk\"], # the predicted outcome\n",
        "                         sensitive_features=df_filtered[\"race\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-fW8t5-5SSe",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:18.084867500Z",
          "start_time": "2023-05-24T19:00:17.612278800Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_by_race.by_group.plot.bar(subplots=True, figsize=(10, 14))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xof-7MiS5SSe"
      },
      "source": [
        "It is also possible to easily **operate with these metrics** through some built-in functions.\n",
        "\n",
        "For instance, let's calculate the maximum metrics difference between groups:\n",
        "\n",
        "Does these results for FNR and FPR match our manual calculations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgp14CVZ5SSe",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:18.647102Z",
          "start_time": "2023-05-24T19:00:18.629096400Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_by_race.difference(method='between_groups')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw--OEcm5SSe"
      },
      "source": [
        "It's also possible to define **control features** for the analysis. A controlled feature has its value fixed, so that its variability cannot affect the calculated metrics for the sensitive groups.\n",
        "\n",
        "Let's use `age_cat` as controlled feature, now over the race-filtered dataframe as defined in the above exercise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3nVwIBv5SSf",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:19.682262900Z",
          "start_time": "2023-05-24T19:00:19.548262900Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_race_agecontrolled = MetricFrame(metrics,\n",
        "                                    df_filtered[\"is_recid\"],  # the real outcome\n",
        "                                    df_filtered[\"high_risk\"], # the predicted outcome\n",
        "                                    sensitive_features=df_filtered[\"race\"],\n",
        "                                    control_features=df_filtered[\"age_cat\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA002cjq5SSg"
      },
      "source": [
        "Now, the `overall` resoults are distributed based on the controlled feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b08NAz45SSh",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:20.454141300Z",
          "start_time": "2023-05-24T19:00:20.442107100Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_race_agecontrolled.overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR9NXf6p5SSh"
      },
      "source": [
        "**Exercise**: Spend a couple of minutes analysing the following metric values by group. Is there any value that seems way off?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G-71RQA5SSh",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:21.257851500Z",
          "start_time": "2023-05-24T19:00:21.231807500Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_race_agecontrolled.by_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PVGSe225SSh",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:22.200745200Z",
          "start_time": "2023-05-24T19:00:22.163013800Z"
        }
      },
      "outputs": [],
      "source": [
        "mf_race_agecontrolled.difference(method='between_groups')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arw88w5D5SSh"
      },
      "source": [
        "# (Optional) Another tool to analyse fairness of different metrics: Aequitas\n",
        "\n",
        "[Aequitas](http://aequitas.dssg.io/) is an open-source bias and fairness auditing toolkit to search for discrimination and bias in machine learning models. You can check its documentation [here](https://dssg.github.io/aequitas/). They have a [notebook example](https://colab.research.google.com/github/dssg/aequitas/blob/update_compas_notebook/docs/source/examples/compas_demo.ipynb) where they demonstrate their tool over the COMPAS dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRQeChdT5SSh",
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:51.438100Z",
          "start_time": "2023-05-24T19:00:25.957554800Z"
        }
      },
      "outputs": [],
      "source": [
        "!pip install aequitas\n",
        "from aequitas.group import Group\n",
        "from aequitas.bias import Bias\n",
        "from aequitas.fairness import Fairness\n",
        "import aequitas.plot as ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez8lqg015SSi",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:52.205967900Z",
          "start_time": "2023-05-24T19:00:51.439099300Z"
        }
      },
      "outputs": [],
      "source": [
        "# Same COMPAS dataset\n",
        "# Some columns need to have specific names, so for brevity we just use the provided version\n",
        "df_aeq = pd.read_csv(\"https://github.com/dssg/aequitas/raw/master/examples/data/compas_for_aequitas.csv\")\n",
        "df_aeq.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghESasUp5SSi"
      },
      "source": [
        "`label_value` is the true outcome (i.e. `is_recid`), while `score` is the predicted value (`high_risk`)\n",
        "\n",
        "Aequitas includes facilities to do the same metrics calculations as we have done above with fairlearn. These metrics are obtained through an instance of the `Group` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne4oTh0E5SSi",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:52.348966400Z",
          "start_time": "2023-05-24T19:00:52.210967600Z"
        }
      },
      "outputs": [],
      "source": [
        "g = Group()\n",
        "xtab, _ = g.get_crosstabs(df_aeq) # you can think of aequitas' crosstabs as fairlearn's MetricFrame\n",
        "\n",
        "# Some of the calculated counts:\n",
        "absolute_metrics = g.list_absolute_metrics(xtab)\n",
        "xtab[[col for col in xtab.columns if col not in absolute_metrics]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUHi9psW5SSi",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:52.355966300Z",
          "start_time": "2023-05-24T19:00:52.304966Z"
        }
      },
      "outputs": [],
      "source": [
        "# and calculated metrics\n",
        "xtab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V4jX11M5SSj"
      },
      "source": [
        "Bias and disparities are calculated with an instance of the `Bias` class. Disparity calculations are done with respect to a reference group. According to the following cell above, we use `Caucasian`, `Male` and `25 - 45` as the reference for each categorical feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgPv_dcj5SSj",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:52.386967400Z",
          "start_time": "2023-05-24T19:00:52.335969500Z"
        }
      },
      "outputs": [],
      "source": [
        "b = Bias()\n",
        "bdf = b.get_disparity_predefined_groups(xtab, original_df=df_aeq, \n",
        "                                        ref_groups_dict={'race':'Caucasian', 'sex':'Male', 'age_cat':'25 - 45'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sucR6S3t5SSj",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:52.615390700Z",
          "start_time": "2023-05-24T19:00:52.367970900Z"
        }
      },
      "outputs": [],
      "source": [
        "# View disparity metrics added to dataframe\n",
        "bdf[['attribute_name', 'attribute_value'] +\n",
        "     b.list_disparities(bdf)].style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TccrXKSX5SSj"
      },
      "source": [
        "As looking at the disparities of the table above can be a bit tedious, Aequitas offers some beautiful and interactive visualisations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmfG7F7a5SSl",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:54.018233400Z",
          "start_time": "2023-05-24T19:00:52.482966800Z"
        }
      },
      "outputs": [],
      "source": [
        "metrics = ['fpr','fnr']\n",
        "disparity_tolerance = 1.25 # threshold to determine if there is a disparity of the metrics\n",
        "\n",
        "ap.summary(bdf, metrics, fairness_threshold = disparity_tolerance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kzh62Ni5SSl",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:54.844753900Z",
          "start_time": "2023-05-24T19:00:54.014236700Z"
        }
      },
      "outputs": [],
      "source": [
        "ap.disparity(bdf, metrics, 'race', fairness_threshold = disparity_tolerance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTJrEVHT5SSl"
      },
      "source": [
        "**Exercise**: create visualisations to search for disparities in the age categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u1FGfTw5SSl",
        "ExecuteTime": {
          "end_time": "2023-05-24T19:00:55.699879800Z",
          "start_time": "2023-05-24T19:00:54.831752Z"
        }
      },
      "outputs": [],
      "source": [
        "# Your turn: repeat the above plots around the age_cat feature\n",
        "ap.disparity(bdf, metrics, 'age_cat', fairness_threshold = disparity_tolerance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cXH8BbF5SSl"
      },
      "source": [
        "**Optional Exercise**: try other metrics to check for disparate impact. For instance, the Aequitas notebook uses FDR (False Discovery Rate)\n",
        "\n",
        "FDR = False Positives / Predicted Positives, where Predicted Positives = False Positives + True Positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scE482nT5SSl"
      },
      "outputs": [],
      "source": [
        "# Your turn: try out other metrics that might be interesting!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EOWbpUb5SSl"
      },
      "source": [
        "# Additional resources: Tools for fairness & bias auditing\n",
        "\n",
        "In this notebook we have seen how to audit a machine learning model for some metrics of interest to search for any present discrimination or bias. Once the metrics to analyse are clear, the procedure to check for biases is fairly similar\n",
        "\n",
        "Here you have fairness-oriented tools that can be used to check for biases in our dataset (and more! Some of these tools offer ways to \"fix the unfairness\" of a dataset - you can check that for Fairnet in [this notebook](https://github.com/fairlearn/fairlearn/blob/main/notebooks/Binary%20Classification%20with%20the%20UCI%20Credit-card%20Default%20Dataset.ipynb))\n",
        "\n",
        "- IBM's AI Fairness: [webpage](https://aif360.mybluemix.net/), [Python documentation](https://aif360.readthedocs.io/en/latest/index.html)\n",
        "- Microsoft's fairlearn: [webpage](https://fairlearn.org/), [publication](https://www.microsoft.com/en-us/research/uploads/prod/2020/05/Fairlearn_WhitePaper-2020-09-22.pdf)\n",
        "- Google's What-If tool: [webpage](https://pair-code.github.io/what-if-tool/)\n",
        "- Amazon's Sagemaker Clarify: [webpage](https://aws.amazon.com/sagemaker/clarify/), [article](https://aws.amazon.com/blogs/aws/new-amazon-sagemaker-clarify-detects-bias-and-increases-the-transparency-of-machine-learning-models/)\n",
        "- University of Chicago's Aequitas: [webpage](http://aequitas.dssg.io/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LqHmKVhL9avX",
        "Z96fHtIW8G5z",
        "v0KWNc5y5SSI",
        "erGbrVMH5SSW",
        "1qiYkPZL5SSb",
        "Arw88w5D5SSh"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}