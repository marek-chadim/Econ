{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Mvvl9gjYb60k"},"source":["# Basic Data Processing with Pandas - Part 1\n","\n","**What is Pandas for?**\n","\n","This tool is essentially your data’s home. Through Pandas, you get acquainted with your data by cleaning, transforming, and analyzing it.\n","\n","For example, Pandas can extract the data from  CSV file into a DataFrame — a table, basically — then lets you do things like:\n","\n","- Calculate statistics and answer questions about the data, like:\n","    - What's the average, median, max, or min of each column?\n","    - Does column A correlate with column B?\n","    - What does the distribution of data in column C look like?\n","    \n","    \n","- Clean the data by doing things like removing missing values and filtering rows or columns by some criteria\n","\n","- Visualize the data with help from Matplotlib. Plot bars, lines, histograms, bubbles, and more.\n","\n","- Store the cleaned, transformed data back into a CSV, other file or database"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In this tutorial, we will work with a dataset with information about movies from IMDB. We will use Pandas to answer questions such as:\n","- What are the average ratings of movies by year?\n","- What genres are the most highly rated?\n","- What directors bring the most revenue to the studio?"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Getting Started\n","\n","Pandas is a not a built-in Python library, so we need to install it first. We will use the `pip` package manager to install Pandas. If you are using Colab, Pandas is already installed. If you are using your own computer, you can install Pandas by running the following command:\n","\n","``` !pip install pandas ```\n","\n","The ! tells the notebook to run the following command in the terminal. `pip` is the package manager that comes with Python. Usually, you can install a package by running `pip install <package_name>`.\n","\n","To import pandas, we use the following command:\n","\n","```import pandas as pd ```\n","\n","The `pd` is a common alias for pandas. It is used to save typing and to distinguish pandas from other libraries that are also imported into the notebook."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IDjoE2r7cqVC"},"source":["## Basic Definitions\n","\n","The primary two components of pandas are **Series** and **DataFrame**."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Series\n","\n","A `Series` is essentially a column, and a `DataFrame` is a multi-dimensional table made up of a collection of `Series`:\n","\n","`class pandas.Series(data=None, index=None...)`\n","\n","**data:** Contains data stored in Series.\\\n","**index:** With the `index` argument, you can name your own labels.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":236,"status":"ok","timestamp":1650919132257,"user":{"displayName":"Özge Erten","userId":"04218216191004027561"},"user_tz":-120},"id":"TLjm6DKP4FP7","outputId":"66ad3ccd-0ab1-4e1e-a4c8-b489d953f6cd"},"outputs":[],"source":["import pandas as pd\n","\n","data = [2, 4, 5, 6, 9]\n","\n","series = pd.Series(data, index=[1, 3, 5, 7, 9])\n","\n","print(series)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The `index` is like the row labels of a spreadsheet. It is a list of values that uniquely identify each row. If you don't specify an index, one will be created for you from the data. Any list of values can be used as an index, but it is usually either integers or strings."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["menu = pd.Series([8.5, 3.0, 10.0], index=[\"salad\", \"soup\", \"pizza\"])\n","print(menu)\n","print(menu[\"soup\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"12CJ7c_64AtZ"},"source":["### DataFrame\n","\n","A `DataFrame` is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds with a row (or record) and a column.\n","\n","\n","Let's consider we have a fruit stand that sells apples and oranges. We want to have a column for each fruit and a row for each customer purchase. To organize this as a dictionary for pandas we could do something like:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1650916791947,"user":{"displayName":"Özge Erten","userId":"04218216191004027561"},"user_tz":-120},"id":"U8Fb569dch3Q","outputId":"18236129-e1ab-43db-d335-1d549ee2882b"},"outputs":[],"source":["data = {\n","    \"apples\": [3, 2, 0, 1], \n","    \"oranges\": [0, 3, 7, 2]\n","}\n","\n","print(data)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now converting to a `DataFrame`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1650914369873,"user":{"displayName":"Maryam Mohammadi","userId":"17208229077735617177"},"user_tz":-120},"id":"dnBeTjJ5ecXd","outputId":"a933d5ed-3fef-40f0-9e55-d4ebd0d173ec"},"outputs":[],"source":["purchases = pd.DataFrame(data)\n","\n","print(purchases)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hQJdQXtVexZm"},"source":["**How did that work?**\n","\n","Each (key, value) item in data corresponds to a column in the resulting DataFrame.\n","\n","`class pandas.DataFrame(data=None, index=None, columns=None, dtype=None...)`\n","\n","**data:** Data can be ndarray (structured or homogeneous), Iterable, dict, or DataFrame.\n","\n","**index:** Index to use for resulting frame.\n","\n","**columns:** Column labels to use for resulting frame when data does not have them. If data contains column labels, will perform column selection instead.\n","\n","**dtype:** Data type to force. Only a single dtype is allowed.\n","\n","Let's have customer names as our index:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1650916794670,"user":{"displayName":"Özge Erten","userId":"04218216191004027561"},"user_tz":-120},"id":"4nlMp1mcewAH","outputId":"7f872c9e-173e-4de7-d0a3-ac68a54ee088"},"outputs":[],"source":["purchases = pd.DataFrame(data, index=[\"June\", \"Robert\", \"Lily\", \"David\"])\n","\n","print(purchases)"]},{"cell_type":"markdown","metadata":{"id":"l5mE8Uxoe-dm"},"source":["So now we could locate a customer's order by using their name:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1650914384853,"user":{"displayName":"Maryam Mohammadi","userId":"17208229077735617177"},"user_tz":-120},"id":"1XvczpRHfC0M","outputId":"387332c0-debc-4351-9b68-e65322ee1971"},"outputs":[],"source":["purchases.loc[\"June\"]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UEDVkxJjHeyU"},"source":["### Task: Create a Dataframe with 3 columns and 3 rows. The columns should be named `Name`, `Age`, and `Favorite Color`. Fill in the rows with any data you like. The `Name` column should be the index.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBt1sWzJHrYw"},"outputs":[],"source":["# Task1 solution -- there are different ways of creating the same dataframe. This is just one of them, but other solutions are also correct.\n","data = [[\"Jim\", 30, \"green\"], [\"Pam\", 27, \"yellow\"], [\"Michael\", 45, \"red\"]]\n","df = pd.DataFrame(data, columns=[\"Name\", \"Age\", \"Favourite Colour\"])\n","df\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Loading DataFrames\n","\n","Often, you won't be creating DataFrames from scratch. Instead, you will be loading them from files. Pandas can read a variety of file types using its `pd.read_` functions. CSV files are one of the most common, so we will start there."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jTepKoVqfIaZ"},"source":["## Uploading Data\n","\n","Let's first download and import the dataset we will be working with. First, download the file `IMDB-Movie-Data.csv` from Canvas. \n","\n","Then, upload it to your Colab notebook by clicking on the folder icon on the left side of the screen. Click on the `Upload` button and select the file. You should see the file in the file explorer on the left side of the screen. If you right click on the file, you can copy its path by clicking on `Copy Path`.\n","\n","You can also sync your Google Drive with Colab. To do this, click on the folder icon on the left side of the screen. Click on the `Mount Drive` button. You will be prompted to authenticate your Google account. Once you do that, you will be able to access your Google Drive files from Colab. You can upload the file to your Google Drive and then access it from Colab.\n","\n","If you are using a local Jupyter notebook, you can just save the file in the same directory as your notebook."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Loading CSV Files\n","\n","CSV stands for \"comma-separated values\". CSV files are a common way to store tabular data. They are plain text files with a specific structure. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. The first line of the file usually contains the names of each column.\n","\n","With CSV files, all you need is a single line of code:\n","`pandas.read_csv(filepath)`\n","\n","There are many other arguments you can pass to `read_csv`, but we will only use the `filepath` for now.\n","\n","Use the help function to learn more about `read_csv`:\n","\n","```help(pd.read_csv)``` or ```pd.read_csv?```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KOWZwhaGfOJl"},"outputs":[],"source":["#The default value is index_col=None \n","movies_df = pd.read_csv(\"datasets/IMDB-Movie-Data.csv\")\n","\n","#If we set index_col=0, we're explicitly stating to treat the first column as the index:\n","movies_df = pd.read_csv(\"datasets/IMDB-Movie-Data.csv\", index_col=0)\n","\n","movies_df"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fazW7OgjgXnh"},"source":["## Exporting CSV Files\n","\n","You can export a DataFrame to a CSV file using the `DataFrame.to_csv` method. The method has the following signature:\n","\n","`DataFrame.to_csv(path_or_buf=None, sep=',', columns=None, header=True...)`\n","\n","Use the help function to learn more about `to_csv`:\n","\n","```help(pd.DataFrame.to_csv)``` or ```pd.DataFrame.to_csv?```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FrIhtqlVgW9r"},"outputs":[],"source":["movies_df.to_csv(\"new_file.csv\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n3QQ89s9gwl6"},"source":["# Exploring your DataFrame\n","\n","Now let's learn some ways to explore your DataFrame. First, let's see some methods for checking the data within the DataFrame."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Accessing Data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`DataFrame.head(n)` returns the first n rows of the DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1650774546887,"user":{"displayName":"Maryam Mohammadi","userId":"17208229077735617177"},"user_tz":-120},"id":"1mSHRw9rg5st","outputId":"acef0d68-f87d-4a7c-dacf-08352c6428ba"},"outputs":[],"source":["movies_df.head(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`DataFrame.tail(n)` returns the last n rows of the DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1650774550398,"user":{"displayName":"Maryam Mohammadi","userId":"17208229077735617177"},"user_tz":-120},"id":"ZaWlcCnGhHW1","outputId":"4eafd941-68b6-4734-d88e-d7ab3c26f133"},"outputs":[],"source":["movies_df.tail(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`DataFrame.sample(n)` returns a random sample of n rows from the DataFrame.\n","\n","You can also use `DataFrame.sample(nfrac)` to return a random sample of nfrac fraction (a percentage) of rows from the DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Run this cell a few times to see different samples\n","movies_df.sample(5)\n","# Now sample 5% of the DataFrame"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Accessing Columns\n","\n","You can access a specific column by using the following syntax:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df[\"Title\"]\n","# Or\n","movies_df.Title"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The square brackets + string with column anme syntax works for any column name.\n","\n","The `.` notation only works if the column name is a valid Python variable name. For instance, `df.Movie Title` will not work, but `df.movie_title` will. \n","\n","To make sure your code always works, you can use the square brackets + string syntax."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Accessing Rows\n","\n","You can access a specific row in two ways:\n","\n","- `df.loc` - locates by index name (row label). In our case, the index is the ranking of the movie.\n","- `df.iloc` - locates by numerical index (row number).\n","\n","Note that `df.loc` and `df.iloc` are not methods, but attributes. This means that you don't use parentheses to call them. You just use them like this: `df.loc[1]` or `df.iloc[1]`.\n","\n","The arguments for `df.loc` can also be a list of indices. For example, `df.loc[[1, 2, 3]]` will return the top three ranked movies.\n","\n","Remember that DataFrame indices can also be strings."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Returns the movie with Rank 1\n","print(movies_df.loc[1])\n","# Returns the movie in the first row\n","print(movies_df.iloc[0])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`df.loc` and `df.iloc` also work for accessing columns. For example, `df.loc[1, 'Title']` will return the title of the movie with index 1.\n","\n","You can access all rows for a specific column by using `:` as the first argument. For example, `df.loc[:, 'Title']` will return all the titles."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Task: trying out accessing methods\n","\n","- Change the index of your DataFrame to the column `Title`. Then, use `df.loc` to find out the rating of the movie `The Dark Knight Rises`.\n","- Does slicing work with DataFrames? Try to access rows 10 to 20 using slicing.\n","- Does slicing work with indices that are strings? Try to slice the `Title` index.\n","- Use slicing to access all rows for the columns `Title` and `Rating`.\n","- Use slicing to access all rows in reverse order."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1. \n","movies_df.set_index(\"Title\").loc[\"The Dark Knight Rises\"]\n","\n","# 2. \n","movies_df[10:20]\n","\n","# 3.\n","movies_df.set_index(\"Title\")[\"Guardians of the Galaxy\":\"Sing\"]\n","\n","# 4.\n","movies_df.loc[:, [\"Title\", \"Rating\"]]\n","\n","# 5.\n","movies_df[::-1]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Conditional Selection\n","\n","Pandas makes it easy to select rows based on a condition. For example, if we want to select all the movies with a rating of 8.5 or higher, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df[movies_df[\"Rating\"] >= 8.5]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["You can combine multiple conditions using the operators `&` (and) and `|` (or). For example, if we want to select all the movies with a rating of 8.5 that came out after 2009, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df[(movies_df[\"Rating\"] >= 8.5) & (movies_df[\"Year\"] >= 2010)]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In Pandas, to negate a condition, you use the `~` operator. For example, if we want to select all the movies with a rating of 8.5 or lower, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df[~(movies_df[\"Rating\"] > 8.5)]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Task: conditional selection\n","\n","- Select all movies by director David Yates with a Metascore of 70 or higher.\n","- Check how many movies have both a rating of 8.5 or higher and a Metascore of 70 or higher.\n","- Check how many movies not directed by Ridley Scott were released after 2015 or before 2010."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1. \n","movies_df[(movies_df.Director == \"David Yates\") & (movies_df.Metascore >= 70)]\n","\n","# 2. \n","len(movies_df[(movies_df.Rating >= 8.5) & (movies_df.Metascore >= 70)])\n","\n","# 3.\n","len(movies_df[(movies_df.Director != \"Ridley Scott\") & ((movies_df.Year > 2015) | (movies_df.Year < 2010))])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Querying\n","\n","You can also use the `DataFrame.query` method to select rows based on conditions. For example, if we want to select all the movies with a rating of 8.5 or higher that were released after 2010, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df.query(\"Rating >= 8.5 and Year > 2010\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Both methods work the same way. The only difference is that `DataFrame.query` is more convenient to use when you have a lot of conditions because the syntax is more compact.\n","\n","You can find a nice list of examples of query examples [here](https://sparkbyexamples.com/pandas/pandas-dataframe-query-examples/).\n","\n","**Task:**  Use querying to check how many movies not directed by Ridley Scott were released after 2015 or before 2010."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(movies_df.query(\"Director != 'Ridley Scott' and (Year > 2015 or Year < 2010)\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Basic Statistics\n","\n","Pandas makes it easy to calculate basic statistics for your DataFrame. Let's start by calculating a descriptive overview of the numerical columns in our DataFrame.\n","\n","We can do that by using the `DataFrame.describe` method. This method returns a DataFrame with the following statistics:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can also calculate the mean, median, and standard deviation of a column using the `DataFrame.mean`, `DataFrame.median`, and `DataFrame.std` methods.\n","\n","### Task: basic statistics\n","- Compare the mean, median, and standard deviation of the `Metascore` and `Rating` columns.\n","- Calculate the mean revenue of movies directed by Christopher Nolan.\n","- Compare the average runtime of Comedy and Horror movies."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1.\n","movies_df[[\"Metascore\", \"Rating\"]].describe() \n","\n","# 2.\n","movies_df.query(\"Director == 'Christopher Nolan'\")[\"Revenue (Millions)\"].mean()\n","\n","# 3.\n","print(movies_df.query(\"Genre == 'Comedy'\")[\"Runtime (Minutes)\"].mean())\n","print(movies_df.query(\"Genre == 'Horror'\")[\"Runtime (Minutes)\"].mean())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Aggregation\n","\n","So far, we have been calculating statistics for a single column. But what if we want to calculate statistics for multiple columns? For that, we can use aggregation methods.\n","\n","In this tutorial, we will learn about the `DataFrame.groupby` method. This method allows us to group rows based on a column and then calculate statistics for each group.\n","\n","For example, if we want to calculate the average rating for each director, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df.groupby(\"Director\")[\"Rating\"].mean()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can analyse multiple columns at the same time by passing a list of column names to `DataFrame.groupby`. For example, if we want to calculate the average rating and Metascore for each director, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df.groupby(\"Director\")[[\"Rating\", \"Metascore\"]].mean()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["There are many other aggregation methods that you can use with `DataFrame.groupby`. You can find a list of them [here](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html).\n","\n","We will learn more about aggregation methods in other tutorials."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Sorting\n","\n","To sort our DataFrame (or a subset of it) by a column, we can use the `DataFrame.sort_values` method. For instance, to sort movies by rating in descending order, we can do the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies_df.sort_values(\"Rating\", ascending=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Putting it all together\n","\n","Now we have learned all the concepts we need to answer our original questions about the data. Go ahead and implement them!\n","\n","- What are the average ratings of movies by year?\n","- What genres are the most highly rated?\n","- What directors bring the most revenue to the studio?\n","\n","**Bonus tasks**:\n","- Create a DataFrame with the 10 best rated and the 10 worst rated movies. Save it as a CSV file.\n","- Select all movies directed by the top 3 highest rated (by Metascore) directors.\n","- Find how many unique directors are there in the dataset.\n","- Find out the number of movies released by year in the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1.\n","movies_df.groupby(\"Year\")[\"Rating\"].mean().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2.\n","movies_df.groupby(\"Genre\")[\"Rating\"].mean().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 3.\n","movies_df.groupby(\"Director\")[\"Revenue (Millions)\"].mean().sort_values(ascending=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Bonus tasks\n","\n","There are different ways to solve these tasks. These solutions are using methods we will learn in the next tutorials."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1. \n","# We first sort the dataframe by Rating in descending order\n","movies_df_by_rating = movies_df.sort_values(\"Rating\", ascending=False)\n","# Then we create a new one by concatenating the first 10 rows with the last 10 rows. Check the documentation for pd.concat!\n","new_df = pd.concat([movies_df_by_rating.head(10), movies_df_by_rating.tail(10)])\n","new_df.to_csv(\"top_and_bottom_10.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2.\n","# We first select the top 3 directors by mean metascore\n","top_3_directors = movies_df.groupby(\"Director\")[\"Metascore\"].mean().sort_values(ascending=False).head(3).index\n","# Then we query the dataframe to only keep the rows where the director is in the top 3\n","movies_df.query(\"Director in @top_3_directors\")\n","# We can also use the isin() method. Check the documentation for more info!\n","movies_df[movies_df[\"Director\"].isin(top_3_directors)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 3.\n","movies_df.Director.nunique()\n","# This is the same as doing: \n","len(movies_df.Director.unique())\n","# But nunique() is much more readable, so it's better to use it"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 4.\n","# The count function counts the number of non-null values in a column\n","movies_df.groupby(\"Year\").count()[\"Title\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Tutorial 5: Basic data processing with pandas .ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"vscode":{"interpreter":{"hash":"1877f673086dc809c707ab8b7edd49e4d1baba779fb6e8a204f0f5a77fae4dba"}}},"nbformat":4,"nbformat_minor":0}
