{"cells":[{"cell_type":"markdown","metadata":{"id":"P9hC7S-ZOEN_"},"source":["# Advanced Data Processing with Pandas\n","\n","We have learned many useful Pandas functions in the previous tutorials. \n","\n","In this tutorial, we will apply everything we have learned to a more challenging data science problem. Instead of just using the dataset and assuming it is \"correct\", we will have to combine data from different sources and clean it up to make it useful for our analysis.\n","\n","**The Task**\n","- We will expand our original IMDB dataset to include more movies, from a different `csv` file.\n","- We will have to analyse both data sources to find out how to combine them.\n","- We will explore our new dataset and find if there are any missing or duplicated values."]},{"cell_type":"markdown","metadata":{"id":"dGrcvd_5OEOC"},"source":["# Getting Started\n","\n","Before we start using the new dataset, let's load the original one again and learn a few more functions that will be useful for our task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAeEo9CZOEOD"},"outputs":[],"source":["import pandas as pd\n","\n","movies_df_original = pd.read_csv(\"datasets/IMDB-Movie-Data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tloUWhPgOEOE"},"outputs":[],"source":["movies_df_original.head(5)"]},{"cell_type":"markdown","metadata":{"id":"2gGVRDz7OEOE"},"source":["# Finding Missing Values\n","\n","In the previous tutorials, we noticed that some values in our dataset were NaN (Not a Number). This is a special value that Pandas uses to indicate that a value is missing.\n","\n","We can systematically check for missing values in a DataFrame using the `isna()` function. This function returns a DataFrame of the same size as the original, but with boolean values. A value is `True` if the original value was NaN, and `False` otherwise.\n","\n","Let's see how it works in practice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aA-sdqaVOEOF"},"outputs":[],"source":["movies_df_original.isna()"]},{"cell_type":"markdown","metadata":{"id":"ftI96tsbOEOF"},"source":["The function works on a row-level. We can aggregate the results to check which columns have missing values.\n","\n","How do we aggregate the results?"]},{"cell_type":"markdown","metadata":{"id":"I4TPeThJOEOF"},"source":["### `any()`\n","\n","The `any()` functions returns `True` if any (i.e., at least one) of the values in the row are `True`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLNeZ8FUOEOG"},"outputs":[],"source":["movies_df_original.isna().any()"]},{"cell_type":"markdown","metadata":{"id":"n8zRABn0OEOG"},"source":["So we know that `Revenue (Millions)` and `Metascore` have missing values. But how many are missing in total?"]},{"cell_type":"markdown","metadata":{"id":"h0C7Twq8OEOH"},"source":["### `sum()`\n","\n","The `sum()` function returns the sum of all the values in a row. For boolean values, `True` is treated as `1` and `False` as `0`. So we can use `sum()` to count the number of `True` values in a row."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtavDT0QOEOH"},"outputs":[],"source":["movies_df_original.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"zImbs3pUOEOH"},"source":["# Handling Missing Values\n","\n","We have seen that there are missing values in our dataset. But how do we deal with them?\n","\n","It is important to think about what a *missing value* means in the context of our dataset. For instance, if a Metascore is missing, it could mean that the movie was not rated by the Metacritic website.  If a Revenue value is missing, it could mean that the movie was not released yet or simply that the information is not available.\n","\n","With that in mind, we have two main options to handle missing values: removing or filling them. \n","\n","The best one depends on the situation and on the dataset. "]},{"cell_type":"markdown","metadata":{"id":"NG5FEUk9OEOI"},"source":["### Option 1: Remove the rows with missing values\n","\n","We can assume that if a value is missing, the entire row is not useful for our analysis. If we are analysing the average Metascore per genre and a movie does not have this value, it is not useful to consider it for this.\n","\n","We can remove the rows with missing values using the `dropna()` function.\n","\n","`dropna()` has a `how` parameter that can be set to `any` or `all`. The default value is `any`, which means that a row will be removed if any of its values are missing. If we set it to `all`, a row will be removed only if all of its values are missing.\n","\n","Let's try it out and remove all the rows with any missing values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C18x7o8ROEOI"},"outputs":[],"source":["movies_df_original.dropna(how=\"any\")"]},{"cell_type":"markdown","metadata":{"id":"y92h6YNCOEOI"},"source":["If we remove all rows with any missing values, we drop 162 rows. *How do we calculate this?*\n","\n","We can also remove all rows with missing values in specific columns. For that, we can use the `subset` parameter and pass a list of column names.\n","\n","Let's remove all rows with missing values in the `Revenue (Millions)` column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqHZloVfOEOI"},"outputs":[],"source":["movies_df_original.dropna(subset=[\"Revenue (Millions)\"], how=\"any\")"]},{"cell_type":"markdown","metadata":{"id":"fKNE4wgpOEOJ"},"source":["In this case, we drop 128 rows.\n","\n","Remember that unless we set `inplace=True`, we are not modifying the original DataFrame. So we either need to assign the result to a new variable or set `inplace=True`."]},{"cell_type":"markdown","metadata":{"id":"7WvTLkguOEOJ"},"source":["### Option 2: Fill the missing values\n","\n","Another option is to fill the missing values with some other value. This is useful if we want to keep all rows.\n","\n","There are different ways to fill the missing values. We can fill them with a constant value, or we can fill them with the mean, median or mode of the column.\n","\n","Again, the best option depends on the situation and on the dataset.\n","\n","The `fillna()` function can be used to fill the missing values. It has a `value` parameter that can be set to a constant value, or to a function that will be applied to the column.\n","\n","We can apply it directly to a specific column.\n","\n","Let's fill the missing values in the `Metascore` column with the mean value.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tg-ubNtiOEOJ"},"outputs":[],"source":["movies_df_original[\"Metascore\"].fillna(movies_df_original[\"Metascore\"].mean())"]},{"cell_type":"markdown","metadata":{"id":"zcsfpirkOEOJ"},"source":["#### Task: check the descriptive statistics of the `Metascore` column before and after filling the missing values. What happened?\n","\n","Check it again after filling the missing values with 0."]},{"cell_type":"markdown","metadata":{"id":"8IjNtGeoOEOJ"},"source":["#### Task: do the same for the `Revenue (Millions)` column."]},{"cell_type":"markdown","metadata":{"id":"aEWrJkhkOEOK"},"source":["You can also apply `fillna()` to the entire DataFrame. In this case, the function will fill the missing values in all columns.\n","\n","You should be careful when using this option, because it will fill all missing values, even if they are not supposed to be filled. For instance, if we fill the missing values in the `Genre` column, we will replace the missing values with the mean value of the column, which is not correct."]},{"cell_type":"markdown","metadata":{"id":"UKyZtQNVOEOK"},"source":["# Handling Duplicate Values\n","\n","We can also check if there are duplicate values in our dataset. Duplicate values are rows that have the same values in all (or a subset of) columns.\n","\n","If different rows have the exact same values in all columns, it is safe to assume they are duplicates. But if different rows have the same values in some columns, it is not clear if they are duplicates or not. For instance, if two movies have the same title, they could still be different. However, in our dataset, this is very unlikely.\n","\n","To check for duplicate values, we can use the `duplicated()` function. This function returns a Series of boolean values, with one value for each row. A value is `True` if the row is a duplicate, and `False` otherwise. It works very similarly to `isna()`.\n","\n","Let's check if there are any duplicate values in our dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoAl8ke9OEOK"},"outputs":[],"source":["movies_df_original.duplicated().sum()"]},{"cell_type":"markdown","metadata":{"id":"yRER5NXPOEOK"},"source":["There are no duplicate values in our dataset. But let's test it for one column just to see how it works.\n","\n","Let's check if there are any duplicate (Director, Year) pairs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJOrp0OYOEOK"},"outputs":[],"source":["movies_df_original.duplicated(subset=[\"Director\", \"Year\"]).sum()"]},{"cell_type":"markdown","metadata":{"id":"GcGikQ5mOEOK"},"source":["That means 13 rows have the same Director and Year as another row. Of course they are not duplicates, because they are different movies, so we don't need to remove them.\n","\n","But in case we wanted to remove them, we could use the `drop_duplicates()` function.\n","\n","It works very similarly to `dropna()`. We can use the `subset` parameter to specify which columns to consider when checking for duplicates.\n","\n","If we had duplicates in our dataset, we could remove them like this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EB81KHagOEOL"},"outputs":[],"source":["movies_df_original.drop_duplicates(subset=[\"Director\", \"Year\"], keep=\"first\")"]},{"cell_type":"markdown","metadata":{"id":"Wmy7PxePOEOL"},"source":["The `keep` parameter can be set to `first` or `last`. If we set it to `first`, the first row will be kept and the rest will be removed. If we set it to `last`, the last row will be kept and the rest will be removed."]},{"cell_type":"markdown","metadata":{"id":"_cNW-LKdOEOL"},"source":["# Combining Datasets\n","\n","It's time to use our new dataset! Let's first load it and take a look at it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEyphduvOEOL"},"outputs":[],"source":["movies_df_new = pd.read_csv(\"datasets/imdb_5k.csv\")\n","movies_df_new.head(5)"]},{"cell_type":"markdown","metadata":{"id":"BiIjDgwkOEOL"},"source":["The columns are completely different! So we can't just combine the two datasets. We need to decide which columns to keep and which to remove.\n","Now it's time to work as real data scientist and investigate the data carefully."]},{"cell_type":"markdown","metadata":{"id":"COKuJwxcOEOL"},"source":["#### Task: have a look at the columns in the new dataset and figure out what they mean."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ct8RkAoAOEOL"},"outputs":[],"source":["print(movies_df_original.columns)\n","print(movies_df_new.columns)"]},{"cell_type":"markdown","metadata":{"id":"MD5-9J9kOEOM"},"source":["### Task: select at least 5 columns that are present in both datasets."]},{"cell_type":"markdown","metadata":{"id":"xV1KtNshOEOM"},"source":["## Concatenating Datasets\n","\n","If we want to simply add one dataset to the other, we can use the `concat()` function.\n","\n","In this case, Pandas will just add the rows of the second dataset to the end of the first one.\n","\n","Let's see how the output looks like."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VexUbM_rOEOM"},"outputs":[],"source":["movies_df_combined = pd.concat([movies_df_original, movies_df_new])\n","movies_df_combined.tail(5)"]},{"cell_type":"markdown","metadata":{"id":"NcubmnI0OEOM"},"source":["That doesn't look good... Since the columns don't match, Pandas added a lot of missing values.\n","\n","Let's do two things:\n","- Decide which columns to keep and rename them to a common name (using the `rename()` function\n","- Concatenate the two datasets again"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPcGJJ10OEOM"},"outputs":[],"source":["# Columns from the original dataframe. Let's keep using these names and rename the corresponding columns in the new dataframe.\n","columns_to_keep = [\"Title\", \"Year\", \"Director\", \"Rating\", \"Revenue (Millions)\"]\n","rename_mapping = {\"movie_title\": \"Title\", \"title_year\": \"Year\", \"director_name\": \"Director\", \"imdb_score\": \"Rating\", \"gross\": \"Revenue (Millions)\"}\n","# Now let's rename the columns in the new dataframe.\n","movies_df_new.rename(columns=rename_mapping, inplace=True)\n","# Now let's concatenate the dataframes using only the columns we want to keep.\n","movies_df_combined = pd.concat([movies_df_original[columns_to_keep], movies_df_new[columns_to_keep]])\n","movies_df_combined.tail(5)"]},{"cell_type":"markdown","metadata":{"id":"5u3qaoUxOEOM"},"source":["It looks much better now!\n","\n","However, we might have added some duplicate rows. The new dataset might have movies that are already in the old dataset."]},{"cell_type":"markdown","metadata":{"id":"qlL3v_qjOEOM"},"source":["#### Task: check if there are any duplicate rows in the new dataset and remove them."]},{"cell_type":"markdown","metadata":{"id":"4GpmapZJOEON"},"source":["This was not the only problem..."]},{"cell_type":"markdown","metadata":{"id":"kXCHv7AnOEON"},"source":["#### Task: investigate the combined dataset and figure out at least three other issues we need to fix.\n","\n","**Hint:** have a look at the index."]},{"cell_type":"markdown","metadata":{"id":"uuVMR2aGOEON"},"source":["### Fixing potential issues\n","\n","We will do three things:\n","- Fix the index\n","- Fix the column types\n","- Handle missing values"]},{"cell_type":"markdown","metadata":{"id":"f80PpRrpOEON"},"source":["#### Fixing the index\n","\n","The index is not correct. It should be unique for each row, but it is not. We can fix it by resetting it.\n","\n","The `reset_index()` function will reset the index and create a new column with the old index values, in case we need to use them later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Het2VI8-OEON"},"outputs":[],"source":["movies_df_combined.reset_index(inplace=True)\n","movies_df_combined.tail(5)"]},{"cell_type":"markdown","metadata":{"id":"1F-ZuKL_OEON"},"source":["#### Fixing the column types\n","\n","In our original dataset, the `Year` column was an integer. But in the new dataset, it is a float. When we concatenated the two datasets, Pandas converted the column to a float.\n","\n","However, it makes more sense to keep it as an integer. We can convert it using the `astype()` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaFTRD9aOEON"},"outputs":[],"source":["movies_df_combined[\"Year\"] = movies_df_combined[\"Year\"].astype(int)\n","movies_df_combined.head(5)"]},{"cell_type":"markdown","metadata":{"id":"5LuZP64tOEON"},"source":["That didn't work... Why?\n","\n","Some years are missing, and we can't convert NaN to an integer.\n","\n","We need first handle the missing values. Then we come back to this."]},{"cell_type":"markdown","metadata":{"id":"b_WEUuA_OEOO"},"source":["#### Handling missing values\n","\n","We already saw that the missing values in the `Year` column are not a critical. In this case, it makes sense to remove them.\n","\n","Let's do that."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtinZpAGOEOO"},"outputs":[],"source":["movies_df_combined.dropna(subset=[\"Year\"], how=\"any\", inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"y4N-HVQdOEOO"},"source":["Now let's try to convert the column to an integer again."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VES_aLXKOEOO"},"outputs":[],"source":["movies_df_combined[\"Year\"] = movies_df_combined[\"Year\"].astype(int)\n","movies_df_combined.head(5)"]},{"cell_type":"markdown","metadata":{"id":"A6JO7Vp7OEOO"},"source":["Now it works!"]},{"cell_type":"markdown","metadata":{"id":"jNgsoigpOEOO"},"source":["#### Task: check what other columns have missing values and decide what to do with them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNfhPL2POEOO"},"outputs":[],"source":["movies_df_combined"]},{"cell_type":"markdown","metadata":{"id":"w0Y6FmkKOEOP"},"source":["Now we have a nice combined dataset!\n","\n","Time to answer the quiz."]},{"cell_type":"markdown","metadata":{"id":"Yj0jodMoOEOP"},"source":["# !!! QUIZ !!!"]},{"cell_type":"markdown","metadata":{"id":"Q42R4ylzOEOP"},"source":["# Adding more Information\n","\n","There are more columns that are present in both datasets. Let's add at least genre and runtime."]},{"cell_type":"markdown","metadata":{"id":"Jiq8hAvAOEOP"},"source":["#### Task: map the genre and runtime columns from the old dataset to the new one. \n","\n","Use the same approach as before and rename the columns to a common name."]},{"cell_type":"markdown","metadata":{"id":"dIhKp73KOEOP"},"source":["#### Task: create a new combined dataset including the seven columns we selected."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTHkCVHTOEOP"},"outputs":[],"source":["# Columns from the original dataframe. Let's keep using these names and rename the corresponding columns in the new dataframe.\n","columns_to_keep = [\"Title\", \"Year\", \"Director\", \"Rating\", \"Revenue (Millions)\", \"Genre\", \"Runtime (Minutes)\"]\n","rename_mapping = {\"movie_title\": \"Title\", \"title_year\": \"Year\", \"director_name\": \"Director\", \"imdb_score\": \"Rating\", \"gross\": \"Revenue (Millions)\", \"genres\": \"Genre\", \"duration\": \"Runtime (Minutes)\"}\n","# Now let's rename the columns in the new dataframe.\n","movies_df_new.rename(columns=rename_mapping, inplace=True)\n","# Now let's concatenate the dataframes using only the columns we want to keep.\n","movies_df_combined = pd.concat([movies_df_original[columns_to_keep], movies_df_new[columns_to_keep]])\n","movies_df_combined.tail(5)"]},{"cell_type":"markdown","metadata":{"id":"ppIQMBMwOEOP"},"source":["#### Task: Fix the index and the runtime colum (the values should be integers)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpfA9NTeOEOP"},"outputs":[],"source":["movies_df_combined.reset_index(inplace=True)\n","movies_df_combined.dropna(subset=[\"Year\"], how=\"any\", inplace=True)\n","movies_df_combined.dropna(subset=[\"Runtime (Minutes)\"], how=\"any\", inplace=True)\n","movies_df_combined[\"Runtime (Minutes)\"] = movies_df_combined[\"Runtime (Minutes)\"].astype(int)\n","movies_df_combined.tail(5)"]},{"cell_type":"markdown","metadata":{"id":"fxw9QrltOEOP"},"source":["#### Task: fix the genre column. The values should be separated by commas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWp6WkhaOEOQ"},"outputs":[],"source":["movies_df_combined[\"Genre\"] = movies_df_combined[\"Genre\"].str.replace(\"|\", \",\")\n","movies_df_combined.tail(5)"]},{"cell_type":"markdown","metadata":{"id":"FycCqtolOEOQ"},"source":["# Bonus Tasks\n","\n","Using the most recent dataset, answer the following questions:"]},{"cell_type":"markdown","metadata":{"id":"IhAKJTyMOEOQ"},"source":["### Find out which directors were included in the combined dataset.\n","\n","What is their average IMDB rating?"]},{"cell_type":"markdown","metadata":{"id":"xl6423bVOEOQ"},"source":["### What is the average runtime of movies released in the last 10 years?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xvn86PVOEOQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8cJ-JxKMOEOQ"},"source":["### Are movies getting shorter? Plot the average runtime of movies released in each year."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mogdw9H_OEOQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yCTpa6GlOEOQ"},"source":["### Compare the median runtime of Documentaries and Comedy movies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UURrJ9sEOEOQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"i1BKkdTrOEOQ"},"source":["### Which director directed the most movies with different genres?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcQpCddPOEOR"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"lRKzHfiiOEOR"},"source":["### What year had the highest average IMDB rating? And the lowest?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmS11TVEOEOR"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4,"colab":{"provenance":[],"collapsed_sections":["P9hC7S-ZOEN_","dGrcvd_5OEOC","2gGVRDz7OEOE","I4TPeThJOEOF","h0C7Twq8OEOH","zImbs3pUOEOH","NG5FEUk9OEOI","7WvTLkguOEOJ","zcsfpirkOEOJ","8IjNtGeoOEOJ","UKyZtQNVOEOK","_cNW-LKdOEOL","COKuJwxcOEOL","MD5-9J9kOEOM","xV1KtNshOEOM","qlL3v_qjOEOM","kXCHv7AnOEON","uuVMR2aGOEON","f80PpRrpOEON","1F-ZuKL_OEON","b_WEUuA_OEOO","jNgsoigpOEOO","Yj0jodMoOEOP","Q42R4ylzOEOP","Jiq8hAvAOEOP","dIhKp73KOEOP","ppIQMBMwOEOP","fxw9QrltOEOP","FycCqtolOEOQ","IhAKJTyMOEOQ","xl6423bVOEOQ","8cJ-JxKMOEOQ","yCTpa6GlOEOQ","i1BKkdTrOEOQ","lRKzHfiiOEOR"]}},"nbformat":4,"nbformat_minor":0}