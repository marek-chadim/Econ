{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv3Z2tuiOUbY"
      },
      "source": [
        "# Machine Learning with Python: Part 2\n",
        "\n",
        "In this tutorial, we will work on a dataset about bank loans. We will use the data to predict whether a loan will be given to an applicant. \n",
        "\n",
        "We will learn about the following topics in this tutorial:\n",
        "- Encoding categorical variables\n",
        "- Cross-validation\n",
        "- Hyperparameter tuning\n",
        "- Feature selection\n",
        "\n",
        "Let's start by loading the dataset and taking a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i2LBECRNOUbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>married</th>\n",
              "      <th>dependents</th>\n",
              "      <th>education</th>\n",
              "      <th>self_employed</th>\n",
              "      <th>applicant_income</th>\n",
              "      <th>coapplicant_income</th>\n",
              "      <th>loan_amount</th>\n",
              "      <th>term</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>area</th>\n",
              "      <th>loan_given</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>584900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>458300</td>\n",
              "      <td>150800.0</td>\n",
              "      <td>12800000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>300000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6600000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>258300</td>\n",
              "      <td>235800.0</td>\n",
              "      <td>12000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14100000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  gender married dependents     education self_employed  applicant_income   \n",
              "0   Male      No          0      Graduate            No            584900  \\\n",
              "1   Male     Yes          1      Graduate            No            458300   \n",
              "2   Male     Yes          0      Graduate           Yes            300000   \n",
              "3   Male     Yes          0  Not Graduate            No            258300   \n",
              "4   Male      No          0      Graduate            No            600000   \n",
              "\n",
              "   coapplicant_income  loan_amount   term  credit_history   area loan_given  \n",
              "0                 0.0     15000000  360.0             1.0  Urban          Y  \n",
              "1            150800.0     12800000  360.0             1.0  Rural          N  \n",
              "2                 0.0      6600000  360.0             1.0  Urban          Y  \n",
              "3            235800.0     12000000  360.0             1.0  Urban          Y  \n",
              "4                 0.0     14100000  360.0             1.0  Urban          Y  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"loans.csv\")\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X6WMkCx8OUbd"
      },
      "source": [
        "The dataset contains information about loan applicants, including their gender, marital status, number of dependents, education level, employment status, income, loan amount, loan term, credit history, area, and whether a loan was given or not.\n",
        "\n",
        "The column `loan_given` is our target variable (the variable we want to predict). The other columns are our features (the variables we use to predict the target variable)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G0iwO0RLOUbe"
      },
      "source": [
        "# Cleaning the Data\n",
        "\n",
        "Before we can use the data for machine learning, we need to clean it. Let's handle missing values first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R4vOVxSVOUbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender                2.117264\n",
              "married               0.488599\n",
              "dependents            2.442997\n",
              "education             0.000000\n",
              "self_employed         5.211726\n",
              "applicant_income      0.000000\n",
              "coapplicant_income    0.000000\n",
              "loan_amount           0.000000\n",
              "term                  2.280130\n",
              "credit_history        8.143322\n",
              "area                  0.000000\n",
              "loan_given            0.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum() / len(df) * 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ty0iPyi9OUbf"
      },
      "source": [
        "The column with the highest number of missing values is `credit_history`. Still, it is only missing 8.14% of the values, so we can drop the rows with missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H3_NwfTbOUbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender                0.0\n",
              "married               0.0\n",
              "dependents            0.0\n",
              "education             0.0\n",
              "self_employed         0.0\n",
              "applicant_income      0.0\n",
              "coapplicant_income    0.0\n",
              "loan_amount           0.0\n",
              "term                  0.0\n",
              "credit_history        0.0\n",
              "area                  0.0\n",
              "loan_given            0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(inplace=True)\n",
        "df.isna().sum() / len(df) * 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8DV8tJmtOUbf"
      },
      "source": [
        "# Encoding Categorical Variables\n",
        "\n",
        "So far, we have only worked with numerical variables. However, many datasets contain categorical variables. Categorical variables are variables that have a limited number of possible values. For example, the variable `self_employed` in our dataset has two possible values: `Yes` and `No`. The variable `area` has three possible values: `Urban`, `Rural`, and `Semiurban`.\n",
        "\n",
        "Machine learning algorithms cannot work with categorical variables directly. For the computer, the values `Yes` and `No` are just strings. Therefore, we need to convert categorical variables into numerical variables. This process is called **encoding**.\n",
        "\n",
        "There are two main ways to encode categorical variables: **label encoding** and **one-hot encoding**."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K4F8e6qrOUbg"
      },
      "source": [
        "## Label Encoding\n",
        "\n",
        "Label encoding is the process of converting each value of a categorical variable into a number. For example, we can convert the values `Yes` and `No` into the numbers `1` and `0`.\n",
        "\n",
        "Label encoding is suitable for ordinal variables where there is a meaningful order or hierarchy among the categories. For instance, consider a variable `size` with categories `Small`, `Medium`, and `Large`. We can convert these categories into the numbers `0`, `1`, and `2` because there is a meaningful order among them.\n",
        "\n",
        "However, label encoding is not suitable for nominal variables where there is no meaningful order among the categories. For instance, consider a variable `colour` with categories `Red`, `Green`, and `Blue`. We cannot convert these categories into the numbers `0`, `1`, and `2` because we cannot say that one colour is greater than another.\n",
        "\n",
        "**For our dataset, label encoding is not suitable because our categorical variables are nominal variables**. Nevertheless, let's see how we can do label encoding using in Python using the `LabelEncoder` class from the `sklearn.preprocessing` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RlyYIiHZOUbh"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "area = le.fit_transform(df[\"area\"])\n",
        "display(area)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MUtBYC9COUbh"
      },
      "source": [
        "`LabelEncoder` has two main methods: `fit` and `transform`. The `fit` method learns the mapping between the categories and the numbers. The `transform` method applies the mapping to the categories and converts them into numbers.\n",
        "\n",
        "`fit_transform` is a shortcut that combines `fit` and `transform` into a single method."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "02d506pNOUbi"
      },
      "source": [
        "### Task: encode the variables  `married`, `education`, and `self_employed` using label encoding.\n",
        "\n",
        "Challenge: Try to encode all of them in a single line of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnHXaeAaOUbi"
      },
      "outputs": [],
      "source": [
        "df[[\"married\", \"education\", \"self_employed\"]].apply(le.fit_transform)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CWQUkZkvOUbi"
      },
      "source": [
        "## One-Hot Encoding\n",
        "\n",
        "One-hot encoding is the process of converting each value of a categorical variable into a vector of zeros and ones. For example, we can convert the values `Yes` and `No` into the vectors `[1, 0]` and `[0, 1]`.\n",
        "\n",
        "One-hot encoding represents each category as a separate binary feature (or column). Each feature corresponds to a specific category and takes a value of 1 if the observation belongs to that category and 0 otherwise. It is suitable for nominal variables where there is no order or hierarchy among the categories.\n",
        "\n",
        "We can use one-hot encoding for all categorical variables in our dataset. Let's see how we can do one-hot encoding in Python using the `OneHotEncoder` class from the `sklearn.preprocessing` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gJXe7fBOUbi"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "area = ohe.fit_transform(df[[\"area\"]])\n",
        "display(area)\n",
        "display(area.toarray())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bl6Up0o7OUbj"
      },
      "source": [
        "`OneHotEncoder` returns a sparse matrix. A sparse matrix is a matrix that contains mostly zeros. Sparse matrices are useful because they save memory. However, they are not very easy to read.\n",
        "\n",
        "To visualize a sparse matrix, we can convert it into a regular matrix using the `toarray` method.\n",
        "\n",
        "The sparse format is useful when dealing with large datasets that contain a lot of zeros. For our dataset, the sparse format is not necessary."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vWc6uH_UOUbj"
      },
      "source": [
        "### Task: encode all the categorical variables in our dataset using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2mdY486OUbj"
      },
      "outputs": [],
      "source": [
        "categorical_variables = [\"gender\", \"dependents\", \"married\", \"education\", \"self_employed\", \"area\"]\n",
        "onehot_variables = ohe.fit_transform(df[categorical_variables])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WVfv1W9ZOUbj"
      },
      "source": [
        "The function `get_dummies` from pandas can also be used to do one-hot encoding. It returns a regular matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3kLa_FbOUbk"
      },
      "outputs": [],
      "source": [
        "pd.get_dummies(df[\"area\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w-TPh4yJOUbk"
      },
      "source": [
        "It can also be used to do one-hot encoding of the entire dataset at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfrHFjfaOUbk"
      },
      "outputs": [],
      "source": [
        "categorical_variables = [\"gender\", \"dependents\", \"married\", \"education\", \"self_employed\", \"area\"]\n",
        "pd.get_dummies(df, columns=categorical_variables)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7NJmJqOUbk"
      },
      "source": [
        "## Binary Encoding\n",
        "\n",
        "Do we need to encode binary variables? For instance, the column `self_employed` has two possible values: `Yes` and `No`. Can we just use them as they are?\n",
        "\n",
        "The answer is yes*. We can use binary variables as they are, even if they are strings. However, we can also encode them using one-hot encoding. The advantage of one-hot encoding is that it makes it easier to add new categories in the future. For example, if we want to add a new category `Maybe` to the column `self_employed`, we can just add a new column `[0, 0]` to the one-hot encoded matrix.\n",
        "\n",
        "\\* _Actually, it depends. It works for most models in scikit-learn, because sklearn converts binary variables into numbers automatically. But it's not always the case, so it's better to encode binary variables as well to be safe._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e27j4dR8OUbk"
      },
      "outputs": [],
      "source": [
        "pd.get_dummies(df, columns=[\"gender\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E6pRNgLgOUbl"
      },
      "source": [
        "## Combining Numerical and Categorical Variables\n",
        "\n",
        "Once we encode all the categorical variables, we can combine them with the numerical variables to create a single matrix. This matrix will be our feature matrix.\n",
        "\n",
        "Let's see how to do that in Python. Let's use `pd.get_dummies` because it is much easier to use than `OneHotEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qba961YOUbl"
      },
      "outputs": [],
      "source": [
        "df_encoded = pd.get_dummies(df, columns=categorical_variables)\n",
        "X = df_encoded.drop(\"loan_given\", axis=1).values\n",
        "# We do not need to encode the target variable, but it makes evaluation easier later\n",
        "y = df_encoded[\"loan_given\"].apply(lambda x: 1 if x == \"Y\" else 0).values\n",
        "print(X.shape)\n",
        "display(df_encoded.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3lYQc7HiOUbl"
      },
      "source": [
        "### Task: train a decision tree classifier to predict whether a loan will be given to an applicant. Split the data into training and test sets. Use a classification report to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwxdknYhOUbl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import tree\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = tree.DecisionTreeClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "print(classification_report(y_test, model.predict(X_test)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NOzJSLUtOUbl"
      },
      "source": [
        "# Cross-Validation\n",
        "\n",
        "In the previous tutorial, we split the data into training and test sets. We trained the model on the training set and evaluated it on the test set. This approach is called **holdout validation**.\n",
        "\n",
        "Holdout validation is a good approach, but it has one major drawback: it only uses part of the data for training. In our case, we used 80% of the data for training and 20% for testing. This means that we are not using 20% of the data for training. Moreover, the random split might have put most of the difficult examples in the training set and most of the easy examples in the test set. This would make the model look better than it actually is.\n",
        "\n",
        "To solve this problem, we can use **cross-validation**. Cross-validation is a technique that allows us to use all the data for training and testing. It also allows us to evaluate the model on multiple test sets instead of just one test set.\n",
        "\n",
        "There are many types of cross-validation. In this tutorial, we will use **k-fold cross-validation**. In k-fold cross-validation, we split the data into `k` folds (also called splits). Then, we train the model `k` times. Each time, we use a different fold for testing and the remaining folds for training. Finally, we average the results of the k models to get the final result.\n",
        "\n",
        "10-fold and 5-fold cross-validation are the most common types of cross-validation. Let's see how to do it in Python using the `cross_validate` function from the `sklearn.model_selection` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ6A0zHYOUbm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "# Define the scoring metrics\n",
        "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_validate(clf, X, y, cv=5, scoring=metrics)\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R-vi4Kf6OUbm"
      },
      "source": [
        "`cross_validate` takes as input a model, a feature matrix, a target vector, the number of folds, and, optionally, a scoring function (metrics to evaluate the model). It returns a dictionary containing the scores of the model on each fold.\n",
        "\n",
        "Have a look at the dictionary returned by `cross_validate` to understand what is in there.\n",
        "\n",
        "The most important things to look at are the mean and the standard deviation of the scores. The mean tells us how good the model is on average. The standard deviation tells us how consistent the model is. If the standard deviation is high, it means that the model performs very differently on different folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtmTy9OlOUbm"
      },
      "outputs": [],
      "source": [
        "for metric in metrics:\n",
        "    metric_key = f\"test_{metric}\"\n",
        "    print(f\"Mean {metric} : {cv_scores[metric_key].mean():.3f}, std: {cv_scores[metric_key].std():.3f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv_PSXPUOUbm"
      },
      "source": [
        "## Getting the Models\n",
        "\n",
        "By default, the `cross_validate` function only returns the scores of the model. If we want to get the models themselves, we can set the parameter `return_estimator` to `True`.\n",
        "\n",
        "In this case, the returned dictionary will include a key `estimator` that contains the list of models -- one for each fold. \n",
        "\n",
        "We can use these models to make predictions on new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-PA-YzBOUbm"
      },
      "outputs": [],
      "source": [
        "cv_scores = cross_validate(clf, X, y, cv=5, scoring=metrics, return_estimator=True)\n",
        "models = cv_scores[\"estimator\"]\n",
        "print(models)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eh6AGeLOUbn"
      },
      "source": [
        "## Getting the Model with the Best Score\n",
        "\n",
        "We can also get the model with best performance according to a specific metric. \n",
        "\n",
        "Let's get the model with highest F1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLPyeUlFOUbn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the scores for the specified metric\n",
        "scores = cv_scores[\"test_f1\"]\n",
        "# Find the index of the model with the best performance\n",
        "best_model_index = np.argmax(scores)\n",
        "# Get the best model\n",
        "best_model = cv_scores[\"estimator\"][best_model_index]\n",
        "print(best_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AkKmz_mPOUbn"
      },
      "source": [
        "We can now use it to make predictions on new data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P_JS2ogOUbn"
      },
      "outputs": [],
      "source": [
        "best_model.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jLSkJYG2OUbn"
      },
      "source": [
        "## Task: train a logistic regression model to predict whether a loan will be given to an applicant. Use 5-fold cross-validation to evaluate the model.\n",
        "\n",
        "Use F1 score as the evaluation metric. Print the mean and standard deviation of the F1 scores. Also print the highest F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy2IxLX2OUbv"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression()\n",
        "cv_scores = cross_validate(clf, X, y, cv=5, scoring=\"f1\")\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(f\"Mean F1: {cv_scores['test_score'].mean():.3f}, std: {cv_scores['test_score'].std():.3f}, max: {cv_scores['test_score'].max():.3f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yBmTzuToOUbw"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "So far, we have used the default hyperparameters of the models. Hyperparameters are parameters that are not learned during training. They are set before training and remain constant during training. For example, the maximum depth of a decision tree is a hyperparameter. Hyperparameters can have a big impact on the performance of the model.\n",
        "\n",
        "Each model has its own set of hyperparameters. To check the hyperparameters of a model, we can check the documentation of corresponding sklearn class. For example, the documentation of the `DecisionTreeClassifier` class can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
        "\n",
        "We will learn how to optmise the hyperparameters of a model using grid search. Grid search is a technique that allows us to find the best combination of hyperparameters for a model. It works by trying all possible combinations and selecting the best one.\n",
        "\n",
        "Let's see how to do that in Python using the `GridSearchCV` class from the `sklearn.model_selection` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95bGnk3UOUbw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "clf = DecisionTreeClassifier()\n",
        "# Define the parameter grid\n",
        "param_grid = {\"max_depth\": [1, 3, 5, 7, 9]}\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring=\"f1\")\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X, y)\n",
        "# Print the best parameter and best score\n",
        "print(\"Best Parameter:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "htLM0xh8OUbw"
      },
      "source": [
        "We first define the model we are going to optimise. Then, we define the hyperparameters we want to optimise. We put the hyperparameters in a dictionary. The keys of the dictionary are the names of the hyperparameters and the values are the values we want to try. In this case, we want to try 5 values for the maximum depth of the decision tree: 1, 3, 5, 7, and 9.\n",
        "\n",
        "The `GridSearchCV` class takes as input the model, the hyperparameters, the number of folds, and the scoring function. Then, it performs cross-validation for each model considering all possible combinations of hyperparameters. \n",
        "\n",
        "We can then get the best hyperparameters using the `best_params_` attribute, the best score using `best_score_`, and the also best model using `best_estimator_`.\n",
        "\n",
        "We can optimise multiple hyperparameters at the same time. Let's optimise the maximum depth and the minimum number of samples required to split an internal node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylu8rj3jOUbw"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "clf = DecisionTreeClassifier()\n",
        "# Define the parameter grid\n",
        "param_grid = {\"max_depth\": [1, 3, 5, 7, 9], \"min_samples_leaf\": [1, 5, 10]}\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring=\"f1\")\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X, y)\n",
        "# Print the best parameter and best score\n",
        "print(\"Best Parameter:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3u3dzHPyOUbw"
      },
      "source": [
        "In this case, we have 5 values for the maximum depth and 3 values for the minimum number of samples. This means that we will try 15 combinations of hyperparameters.\n",
        "\n",
        "The best score did not change. This means that `min_samples_leaf` did not impact our model, and the default value is good enough.\n",
        "\n",
        "Can we get a better score?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UMkQGmM0OUbx"
      },
      "source": [
        "### Task: select at least one more hyperparameter and optimise it. Print the best hyperparameters and the best score.\n",
        "\n",
        "Try to beat the current best score! (0.872)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxlkPkXMOUbx"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "dt = DecisionTreeClassifier()\n",
        "# Define the parameter grid\n",
        "param_grid = {\"max_depth\": [1, 3, 5, 7, 9], \"min_samples_leaf\": [1, 5, 10], \"min_samples_split\": [2, 5, 10, 15], \"max_features\": [\"sqrt\", \"log2\"]}\n",
        "# Perform grid search with cross-validation\n",
        "grid_search_dt = GridSearchCV(dt, param_grid, cv=5, scoring=\"f1\")\n",
        "# Fit the grid search to the data\n",
        "grid_search_dt.fit(X, y)\n",
        "# Print the best parameter and best score\n",
        "print(\"Best Parameter:\", grid_search_dt.best_params_)\n",
        "print(\"Best Score:\", grid_search_dt.best_score_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xengQtc_OUbx"
      },
      "source": [
        "### Task: now optimise the hyperparameters of a logistic regression model. Print the best hyperparameters and the best score.\n",
        "\n",
        "Can you outperform the decision tree classifier?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyfpESJKOUbx"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "logreg = LogisticRegression()\n",
        "# Define the parameter grid\n",
        "param_grid = {\"C\": [0.1, 1, 10, 100], \"class_weight\": [\"balanced\", None], \"max_iter\": [100, 200, 500]}\n",
        "# Perform grid search with cross-validation\n",
        "grid_search_logreg = GridSearchCV(logreg, param_grid, cv=5, scoring=\"f1\")\n",
        "# Fit the grid search to the data\n",
        "grid_search_logreg.fit(X, y)\n",
        "# Print the best parameter and best score\n",
        "print(\"Best Parameter:\", grid_search_logreg.best_params_)\n",
        "print(\"Best Score:\", grid_search_logreg.best_score_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ixYPq4h4OUbx"
      },
      "source": [
        "### Task: compare the best decision tree classifier and the best logistic regression model. Use a classification report and a confusion matrix to evaluate the models.\n",
        "\n",
        "What are the main differences?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivOCpPkgOUbx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Decision tree\n",
        "print(classification_report(y, grid_search_dt.best_estimator_.predict(X)))\n",
        "display(ConfusionMatrixDisplay.from_estimator(grid_search_dt.best_estimator_, X, y))\n",
        "# Logisitc regression\n",
        "print(classification_report(y, grid_search_logreg.best_estimator_.predict(X)))\n",
        "display(ConfusionMatrixDisplay.from_estimator(grid_search_logreg.best_estimator_, X, y))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xqpFaQKROUbx"
      },
      "source": [
        "There are other ways of optimising hyperparameters. In sklearn, you can also use [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Have a look at the documentation to learn more about them. [This tutorial](https://scikit-learn.org/stable/modules/grid_search.html) provides a nice overview of the different methods."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KQvSKCktOUby"
      },
      "source": [
        "# Feature Selection\n",
        "\n",
        "We have just learned how to optimise the hyperparameters of a model. We can also optimise the features used to train model. This is called **feature selection**. Feature selection is the process of selecting the most important features for a model. It is useful because it can reduce complexity and improve performance.\n",
        "\n",
        "There are [many methods](https://scikit-learn.org/stable/modules/feature_selection.html) for feature selection. In this tutorial, we will learn about `SelectKBest`. `SelectKBest` is a method that selects the `k` best features according to a specific metric.\n",
        "\n",
        "Let's see how it works in sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37kfLgNnOUby"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# Number of features to select\n",
        "k = 5\n",
        "selector = SelectKBest(k=k, score_func=chi2)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "# Get the selected feature indices\n",
        "feature_indices = selector.get_support(indices=True)\n",
        "# Print the selected features\n",
        "selected_features = df_encoded.drop(\"loan_given\", axis=1).columns[feature_indices]\n",
        "print(\"Selected Features:\", selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REb_GiTVOUby"
      },
      "outputs": [],
      "source": [
        "selector.scores_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yiVZYfLsOUby"
      },
      "source": [
        "We are using `chi2` as the scoring function. `chi2` (chi-squared) is a statistical test that measures the dependence between two variables. In this case, it measures the dependence between each feature and the target. The higher the score, the more important the feature.\n",
        "\n",
        "We can check the scores of each feature using the `scores_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGPVzY-DOUbz"
      },
      "outputs": [],
      "source": [
        "print(selector.scores_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-F0sSGDDOUbz"
      },
      "source": [
        "### Task: select the 5 best features and train a decision tree classifier using these features. Print the classification report and the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYB18-7lOUbz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "# Define the scoring metrics\n",
        "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_validate(clf, X_selected, y, cv=5, scoring=metrics)\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(f\"Mean F1: : {cv_scores['test_f1'].mean()}, std: {cv_scores['test_f1'].std()}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1trgzn7POUbz"
      },
      "source": [
        "### Task: do the same thing with a logistic regression model. Which model performs better with fewer features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIpKoT4jkjb6"
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegression()\n",
        "# Define the scoring metrics\n",
        "metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_validate(clf, X_selected, y, cv=5, scoring=metrics)\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(f\"Mean F1: : {cv_scores['test_f1'].mean()}, std: {cv_scores['test_f1'].std()}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NrRciPwGOUbz"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
