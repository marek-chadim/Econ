# Part 1
star <- read_csv('https://ditraglia.com/data/STAR.csv')
# Part 2
final5 <- read_dta('https://ditraglia.com/data/final5.dta',
encoding = 'latin1')
set.seed(92815)
gradebook <- tibble(
student_id = c(192297, 291857, 500286, 449192, 372152, 627561),
name = c('Alice', 'Bob', 'Charlotte', 'Dante',
'Ethelburga', 'Felix'),
quiz1 = round(rnorm(6, 65, 15)),
quiz2 = round(rnorm(6, 88, 5)),
quiz3 = round(rnorm(6, 75, 10)),
midterm1 = round(rnorm(6, 75, 10)),
midterm2 = round(rnorm(6, 80, 8)),
final = round(rnorm(6, 78, 11)))
# Part 1
gradebook |>
select(ends_with('2'))
set.seed(92815)
gradebook <- tibble(
student_id = c(192297, 291857, 500286, 449192, 372152, 627561),
name = c('Alice', 'Bob', 'Charlotte', 'Dante',
'Ethelburga', 'Felix'),
quiz1 = round(rnorm(6, 65, 15)),
quiz2 = round(rnorm(6, 88, 5)),
quiz3 = round(rnorm(6, 75, 10)),
midterm1 = round(rnorm(6, 75, 10)),
midterm2 = round(rnorm(6, 80, 8)),
final = round(rnorm(6, 78, 11)))
# Part 1
gradebook |>
select(ends_with('2'))
# Part 2
gradebook |>
select(contains('erm'))
# Part 3a
starwars |>
select(where(is.character))
# Part 3b
starwars |>
select(contains('_'))
# Part 3c
starwars |>
select(ends_with('color') | where(is.numeric))
# Part 1
gradebook |>
summarize(across(starts_with('quiz'), sd, .names = '{.col}_sd'))
# Part 2
starwars |>
summarize(across(where(is.character), n_distinct, .names = 'n_{.col}s'))
# Part 3
starwars |>
group_by(homeworld) |>
filter(n() > 1) |>
summarize(across(c(sex, species, eye_color), n_distinct))
starwars |>
group_by(homeworld) |>
filter(n() > 1) |>
summarize(across(c(sex, species, eye_color), n_distinct))
# Part 4
starwars |>
group_by(species) |>
filter(n() > 1) |>
summarize(across(where(is.numeric), \(x) median(x, na.rm = TRUE)))
starwars |>
filter(species == 'Kaminoan')
starwars |>
summarize(across(where(is.numeric), SD_IQR, .names = '{.col}_{.fn}'))
SD_IQR <- list(
SD = \(x) sd(x, na.rm = TRUE),
IQR = \(x) IQR(x, na.rm = TRUE)
)
starwars |>
summarize(across(where(is.numeric), SD_IQR, .names = '{.col}_{.fn}'))
star <- star |>
mutate(classtype = case_match(classtype,
1 ~ 'small',
2 ~ 'regular',
3 ~ 'regular+aid'),
race = case_match(race,
1 ~ 'White',
2 ~ 'Black',
3 ~ 'Asian',
4 ~ 'Hispanic',
5 ~ 'Native American',
6 ~ 'Other'),
hsgrad = if_else(hsgrad == 1, 'graduate', 'non-graduate'))
library(tidyverse)
library(janitor)
library(tidyverse)
library(janitor)
kids <- read_csv('https://ditraglia.com/data/child_test_data.csv')
kids <- clean_names(kids)
kids <- kids |>
mutate(mom_education = if_else(mom_hs == 1, 'HS', 'NoHS')) |>
mutate(mom_education = fct_relevel(mom_education, 'NoHS'))
kids <- read_csv('https://ditraglia.com/data/child_test_data.csv')
View(kids)
kids <- clean_names(kids)
View(kids)
kids <- kids |>
mutate(mom_education = if_else(mom_hs == 1, 'HS', 'NoHS')) |>
mutate(mom_education = fct_relevel(mom_education, 'NoHS'))
lm(kid_score ~ mom_iq, kids)
kids |>
mutate(mom_iq = mom_iq - mean(mom_iq)) |>
lm(kid_score ~ mom_iq, data = _)
lm(kid_score ~ I(mom_iq - mean(mom_iq)), kids)
mean(kids$kid_score)
myplot <- kids |>
ggplot(aes(x = mom_age, y = kid_score)) +
geom_point()
myplot
myplot +
geom_smooth(method = 'lm')
myplot +
geom_smooth()
tibble(u_hat = resid(reg)) |>
ggplot(aes(x = u_hat)) +
geom_histogram(binwidth = 5)
reg <- lm(kid_score ~ mom_iq, kids)
tibble(u_hat = resid(reg)) |>
ggplot(aes(x = u_hat)) +
geom_histogram(binwidth = 5)
alpha_hat <- coef(reg)[1]
beta_hat <- coef(reg)[2]
kids_with_residuals <- kids |>
mutate(residuals = kid_score - alpha_hat - beta_hat * mom_iq)
all.equal(kids_with_residuals$residuals, resid(reg),
check.attributes = FALSE)
kids_with_residuals |>
summarize(mean(residuals), cor(residuals, mom_iq))
# Part 1
library(broom)
reg_reverse <- lm(mom_iq ~ kid_score + mom_hs, kids)
reg_reverse |>
tidy() |>
knitr::kable(digits = 2)
reg_reverse |>
glance() |>
knitr::kable(digits = 2)
# Part 2
tidy(reg_reverse) |>
filter(term == 'kid_score') |>
select(estimate, std.error, statistic, p.value) |>
knitr::kable(digits = 2)
kids_augmented <- augment(reg_reverse, kids)
kids_augmented |>
ggplot(aes(x = .fitted, y = mom_iq)) +
geom_point() +
geom_abline(intercept = 0, slope = 1) +
xlab('Fitted Values') +
ylab('Mom IQ')
reg_y_vs_fitted <- lm(mom_iq ~ .fitted, kids_augmented)
reg_y_vs_fitted |>
tidy() |>
knitr::kable()
c(glance(reg_reverse)$r.squared, glance(reg_y_vs_fitted)$r.squared)
# 3a
lm(kid_score ~ mom_iq + mom_education, kids) |>
tidy() |>
knitr::kable(digits = 2, col.names = c('', 'Estimate', 'SE', 't-stat', 'p-value'))
# 3b
lm(kid_score ~ mom_iq * mom_education, kids) |>
tidy() |>
knitr::kable(digits = 2, col.names = c('', 'Estimate', 'SE', 't-stat', 'p-value'))
kids |>
ggplot(aes(x = mom_iq, y = kid_score, color = mom_education)) +
geom_point() +
geom_smooth(method = 'lm', se = FALSE) +
theme_minimal()
# Part 1
library(car)
reg_interact <- lm(kid_score ~ mom_iq * mom_education, kids)
reg_interact |>
tidy() |>
knitr::kable(digits = 2)
restrictions1 <- c('mom_educationHS = 0', 'mom_iq:mom_educationHS = 0')
linearHypothesis(reg_interact, restrictions1)
linearHypothesis(reg_interact, test = 'Chisq', restrictions1)
# Part 2
set.seed(1693)
reg_augmented <- kids |>
mutate(x = rnorm(nrow(kids)), z = mom_iq + rnorm(nrow(kids))) |>
lm(kid_score ~ mom_iq * mom_education + x + z, data = _)
reg_augmented |>
tidy() |>
knitr::kable(digits = 2)
restrictions2 <- c('x = 0', 'z = 0')
linearHypothesis(reg_augmented, restrictions2)
dice_sum <- \() {
# Roll a pair of fair, six-sided dice and return their sum
die1 <- sample(1:6, 1)
die2 <- sample(1:6, 1)
die1 + die2
}
sims <- map_dbl(1:10000, \(i) dice_sum())
nreps <- 10000
sims <- rep(NA_real_, nreps)
for(i in seq_along(sims)) {
sims[i] <- dice_sum()
}
get_avg_after_streak <- function(shots) {
# shots should be a vector of 0 and 1; if not STOP!
stopifnot(all(shots %in% c(0, 1)))
n <- length(shots)
after_streak <- rep(NA, n) # Empty vector of length n
# The first 3 elements of shots by definition cannot
# follow a streak
after_streak[1:3] <- FALSE
# Loop over the remaining elements of shots
for(i in 4:n) {
# Extract the 3 shots that precede shot i
prev_three_shots <- shots[(i - 3):(i - 1)]
# Are all three of the preceding shots equal to 1?
# (TRUE/FALSE)
after_streak[i] <- all(prev_three_shots == 1)
}
# shots[after_streak] extracts all elements of shots
# for which after_streak is TRUE. Taking the mean of
# these is the same as calculating the prop. of ones
mean(shots[after_streak])
}
get_avg_after_streak(c(0, 1, 1, 1, 1, 0, 0, 0))
draw_shots <- function(n_shots, prob_success) {
rbinom(n_shots, 1, prob_success)
}
set.seed(420508570)
mean(draw_shots(1e4, 0.5))
library(tidyverse)
nreps <- 1e4
sim_datasets <- map(1:nreps, \(i) draw_shots(100, 0.5))
sim_estimates <- map_dbl(sim_datasets, get_avg_after_streak)
mean_T <- mean(sim_estimates)
mean_T
mean_T + c(-1, 1) * 3 / (2 * nreps)
sim_results <- pmap(sim_params, run_sim)
# In very short sequences there may be no streaks, leading to an NaN
# Drop these, so we effectively condition on their being at least one
# streak in the sequence
summary_stats <- map_dbl(sim_results, mean, na.rm = TRUE)
summary_stats <- sim_params |>
bind_cols(mean_T = summary_stats) |>
mutate(bias = mean_T - prob_success)
summary_stats |>
knitr::kable(digits = 2)
# In very short sequences there may be no streaks, leading to an NaN
# Drop these, so we effectively condition on their being at least one
# streak in the sequence
summary_stats <- map_dbl(sim_results, mean, na.rm = TRUE)
summary_stats <- sim_params |>
bind_cols(mean_T = summary_stats) |>
mutate(bias = mean_T - prob_success)
summary_stats |>
knitr::kable(digits = 2)
sim_results <- pmap(sim_params, run_sim)
# In very short sequences there may be no streaks, leading to an NaN
# Drop these, so we effectively condition on their being at least one
# streak in the sequence
summary_stats <- map_dbl(sim_results, mean, na.rm = TRUE)
summary_stats <- sim_params |>
bind_cols(mean_T = summary_stats) |>
mutate(bias = mean_T - prob_success)
sim_params <- expand_grid(n_shots = c(50, 100, 200),
prob_success = c(0.4, 0.5, 0.6))
run_sim <- \(n_shots, prob_success, nreps = 1e4) {
map(1:nreps, \(i) draw_shots(n_shots, prob_success)) |>
map_dbl(get_avg_after_streak)
}
sim_results <- pmap(sim_params, run_sim)
# In very short sequences there may be no streaks, leading to an NaN
# Drop these, so we effectively condition on their being at least one
# streak in the sequence
summary_stats <- map_dbl(sim_results, mean, na.rm = TRUE)
summary_stats <- sim_params |>
bind_cols(mean_T = summary_stats) |>
mutate(bias = mean_T - prob_success)
summary_stats |>
knitr::kable(digits = 2)
sim_results <- pmap(sim_params, run_sim)
# In very short sequences there may be no streaks, leading to an NaN
# Drop these, so we effectively condition on their being at least one
# streak in the sequence
summary_stats <- map_dbl(sim_results, mean, na.rm = TRUE)
summary_stats <- sim_params |>
bind_cols(mean_T = summary_stats) |>
mutate(bias = mean_T - prob_success)
summary_stats |>
knitr::kable(digits = 2)
library(tidyverse)
kids <- read_csv('https://ditraglia.com/data/child_test_data.csv')
dat <- kids |>
select(mom.iq, kid.score)
colMeans(dat)
ggplot(kids) +
geom_density(aes(x = mom.iq), fill = 'black', alpha = 0.5)
ggplot(kids) +
geom_density(aes(x = kid.score), fill = 'orange', alpha = 0.5)
ggplot(kids) +
geom_density2d_filled(aes(x = mom.iq, y = kid.score))
A <- matrix(c(2, 1,
1, 4), byrow = TRUE, ncol = 2, nrow = 2)
A %*% t(A)
set.seed(99999)
n <- 1e5
z1 <- rnorm(n)
z2 <- rnorm(n)
z <- cbind(z1, z2)
rm(z1, z2)
x <- cbind(x1 = 2 * z[, 1] +     z[, 2],
x2 =     z[, 1] + 4 * z[, 2])
var(x)
s1 <- 1
s2 <- 2
r <- 0.4
s12 <- r * (s1 * s2)
A <- matrix(c(s1, 0,
s12 / s1, sqrt(s2^2 - s12^2 / s1^2)),
byrow = TRUE, nrow = 2, ncol = 2)
x <- t(A %*% t(z))
colnames(x) <- c('x1', 'x2')
cov(x)
as_tibble(x) |>
ggplot(aes(x1, x2)) +
geom_density2d_filled() +
coord_fixed()
A <- matrix(c(1, 2, 3,
2, 2, 1,
3, 1, 3),
byrow = TRUE, nrow = 3, ncol = 3)
det(A)
B <- matrix(c(3, 2, 1,
2, 3, 1,
1, 1, 3),
byrow = TRUE, nrow = 3, ncol = 3)
det(B[1:2, 1:2])
R <- chol(B)
L <- t(R)
n_sims <- 1e5
set.seed(29837)
z <- matrix(rnorm(3 * n_sims), nrow = n_sims, ncol = 3)
x <- t(L %*% t(z))
cov(x)
install.packages('mvtnorm')
#install.packages('mvtnorm')
library(mvtnorm)
set.seed(29837)
x_alt <- rmvnorm(n_sims, sigma = B)
cov(x_alt)
set.seed(1234)
n <- 5000
z <- rnorm(n)
library(mvtnorm)
Rho <- matrix(c(1, 0.5,
0.5, 1), 2, 2, byrow = TRUE)
errors <- rmvnorm(n, sigma = Rho)
colMeans(errors)
u <- errors[,1]
v <- errors[,2]
x <- 0.5 + 0.8 * z + v
y <- -0.3 + x + u
cov(x, y) / var(x)
cov(z, y) / var(z)
c(truth = 1,
OLS = cov(x, y) / var(x),
IV = cov(z, y) / cov(z, x),
OLS_x_z = unname(coef(lm(y ~ x + z))[2]))
alpha <- -0.3
beta <- 1
pi0 <- 0.5
pi1 <- 0.8
rho <- 0.5
beta_OLS <- beta + rho / (1 + pi1^2)
alpha_OLS <- alpha - rho * pi0 / (1 + pi1^2)
c(alpha = alpha, beta = beta, alpha_OLS = alpha_OLS, beta_OLS = beta_OLS)
c(alpha = alpha, beta = beta, alpha_OLS = alpha_OLS, beta_OLS = beta_OLS)
coef(AER::ivreg(y ~ x | z))
coef(lm(y ~ x))
c(IV = mean((y - alpha - beta * x)^2),
OLS = mean((y - alpha_OLS - beta_OLS * x)^2))
set.seed(1234)
n <- 10000
R_zw <- matrix(c(1, 0.3, 0.3,
0.3, 1, 0.3,
0.3, 0.3, 1), 3, 3, byrow = TRUE)
zw <- rmvnorm(n, sigma = R_zw)
z1 <- zw[,1]
z2 <- zw[,2]
w <- zw[,3]
R_uv <- matrix(c(1, 0.5,
0.5, 1), 2, 2, byrow = TRUE)
errors <- rmvnorm(n, sigma = R_uv)
u <- errors[,1]
v <- errors[,2]
x <- 0.5 + 0.2 * z1 - 0.15 * z2 + 0.25 * w + v
y <- -0.3 + x - 0.7 * w + u
# TSLS "by hand"
first_stage <- lm(x ~ z1 + z2 + w)
xhat <- fitted.values(first_stage)
second_stage <- lm(y ~ xhat + w)
# TSLS using AER::ivreg
tsls <- AER::ivreg(y ~ x + w | z1 + z2 + w)
library(broom)
library(tidyverse)
tidy(second_stage) |>
knitr::kable(digits = 2, caption = 'Second Stage')
tidy(tsls) |>
knitr::kable(digits = 2, caption = 'TSLS Results')
first_stage <- lm(x ~ z1 + z2)
xhat <- fitted.values(first_stage)
second_stage <- lm(y ~ xhat + w)
coef(second_stage)
AER::ivreg(y ~ x + w | z2 + w) |>
tidy() |>
knitr::kable(digits = 2)
AER::ivreg(y ~ x | z1 + z2) |>
tidy() |>
knitr::kable(digits = 2)
data_url <- 'https://ditraglia.com/data/Ginsburgh-van-Ours-2003.csv'
qe <- read_csv(data_url)
qe <- qe |>
mutate(first = order == 1)
tidy_me <- function(results, mytitle) {
# Helper function for making little tables in this solution
results |>
tidy() |>
select(term, estimate, std.error) |>
knitr::kable(digits = 2, caption = mytitle)
}
lm(ranking ~ first, qe) |>
tidy_me('First stage')
lm(critics ~ first, qe) |>
tidy_me('Reduced Form')
lm(scale(critics) ~ first, qe) |>
tidy_me('Reduced Form - Standardized Outcome')
ols <- lm(critics ~ ranking, qe)
iv <- AER::ivreg(critics ~ ranking | first, data = qe)
tidy_me(ols, 'OLS results')
tidy_me(iv, 'IV results')
ols_scaled <- lm(scale(critics) ~ ranking, qe)
iv_scaled <- AER::ivreg(scale(critics) ~ ranking | first, data = qe)
tidy_me(ols_scaled, 'OLS results - standardized outcome')
tidy_me(iv_scaled, 'IV results - standardized outcome')
library(tidyverse)
n <- 100
s <- sqrt(25)
alpha <- 0.05
crit <- qnorm(1 - alpha)
tibble(mu = seq(0, 2, 0.01)) |>
mutate(kappa = sqrt(n) * mu / s,
power = 1 - pnorm(crit - kappa)) |>
ggplot(aes(x = mu, y = power)) +
geom_line()
library(tidyverse)
set.seed(4321)
n <- 100
x <- runif(n)
error <- rnorm(n, mean = 0, sd = sqrt(2 * x))
intercept <- 0.2
slope <- 0.9
y <- intercept + slope * x + error
tibble(x, y) |>
ggplot(aes(x, y)) +
geom_smooth(method = 'lm') +
geom_point()
library(estimatr)
library(car)
library(broom)
library(modelsummary)
reg_classical <- lm_robust(y ~ x, se_type = 'classical')
reg_robust <- lm_robust(y ~ x, se_type = 'HC0')
modelsummary(list(Classical = reg_classical, Robust = reg_robust),
fmt = 2,
gof_omit = 'R2 Adj.|AIC|BIC')
linearHypothesis(reg_classical, 'x = 0') |> tidy()
linearHypothesis(reg_robust, 'x = 0') |> tidy()
reg <- lm(y ~ x)
uhat <- residuals(reg)
x_demeaned <- x - mean(x)
n <- length(uhat)
# Classical
sigma_sq_hat <- sum(uhat^2) / (n - 2) # two estimated parameters
var_classical <- sigma_sq_hat / sum(x_demeaned^2)
SE_classical <- sqrt(var_classical)
c(lm_robust = tidy(reg_classical) |>
filter(term == 'x') |>
pull(std.error),
by_hand = SE_classical)
# HC0
var_HC0 <- sum(uhat^2 * x_demeaned^2) / (sum(x_demeaned^2)^2)
SE_HC0 <- sqrt(var_HC0)
c(lm_robust = tidy(reg_robust) |>
filter(term == 'x') |>
pull(std.error),  by_hand = SE_HC0)
library(tidyverse)
people <- c("Aiden", "Bella", "Carter", "Dakota", "Ethel", "Floyd",
"Gladys", "Herbert", "Irma", "Julius")
x <- c("young", "young", "young", "young", "old", "old",
"old", "old", "old", "old")
y0 <- c(1, 1, 1, 1, 0, 0, 0, 0, 0, 0)
y1 <- c(1, 1, 1, 1, 1, 0, 0, 1, 0, 0)
d <- c(0, 0, 0, 1, 0, 0, 0, 1, 1, 1)
y <- (1 - d) * y0 + d * y1
tbl <- tibble(name = people, d, y, y0, y1, x)
rm(y0, y1, d, y, x, people)
ATE <- tbl |>
summarize
means <- tbl |>
group_by(d) |>
summarize
(y_mean = mean(y))
